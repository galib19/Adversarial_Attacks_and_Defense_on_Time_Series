{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-24 00:28:42.205977: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-04-24 00:28:42.206002: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.preprocessing\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from keras.layers import Dense,Dropout,LSTM, GRU, SimpleRNN\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers import ConvLSTM2D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.models import Sequential\n",
    "from keras.losses import mean_squared_error\n",
    "from keras.backend import sign\n",
    "import math\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import optimizers\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4324.62</td>\n",
       "      <td>4004.62</td>\n",
       "      <td>4293.85</td>\n",
       "      <td>4148.72</td>\n",
       "      <td>4342.05</td>\n",
       "      <td>4586.67</td>\n",
       "      <td>4097.44</td>\n",
       "      <td>4638.97</td>\n",
       "      <td>4210.77</td>\n",
       "      <td>4226.67</td>\n",
       "      <td>4207.69</td>\n",
       "      <td>4279.49</td>\n",
       "      <td>4632.82</td>\n",
       "      <td>4384.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4327.69</td>\n",
       "      <td>4006.67</td>\n",
       "      <td>4295.38</td>\n",
       "      <td>4156.41</td>\n",
       "      <td>4336.92</td>\n",
       "      <td>4583.59</td>\n",
       "      <td>4096.92</td>\n",
       "      <td>4630.26</td>\n",
       "      <td>4207.69</td>\n",
       "      <td>4222.05</td>\n",
       "      <td>4206.67</td>\n",
       "      <td>4282.05</td>\n",
       "      <td>4628.72</td>\n",
       "      <td>4389.23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4328.72</td>\n",
       "      <td>4011.79</td>\n",
       "      <td>4296.41</td>\n",
       "      <td>4155.90</td>\n",
       "      <td>4343.59</td>\n",
       "      <td>4582.56</td>\n",
       "      <td>4097.44</td>\n",
       "      <td>4630.77</td>\n",
       "      <td>4217.44</td>\n",
       "      <td>4235.38</td>\n",
       "      <td>4210.77</td>\n",
       "      <td>4287.69</td>\n",
       "      <td>4632.31</td>\n",
       "      <td>4396.41</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4326.15</td>\n",
       "      <td>4011.79</td>\n",
       "      <td>4292.31</td>\n",
       "      <td>4151.28</td>\n",
       "      <td>4347.69</td>\n",
       "      <td>4586.67</td>\n",
       "      <td>4095.90</td>\n",
       "      <td>4627.69</td>\n",
       "      <td>4210.77</td>\n",
       "      <td>4244.10</td>\n",
       "      <td>4212.82</td>\n",
       "      <td>4288.21</td>\n",
       "      <td>4632.82</td>\n",
       "      <td>4398.46</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4321.03</td>\n",
       "      <td>4004.62</td>\n",
       "      <td>4284.10</td>\n",
       "      <td>4153.33</td>\n",
       "      <td>4345.64</td>\n",
       "      <td>4587.18</td>\n",
       "      <td>4093.33</td>\n",
       "      <td>4616.92</td>\n",
       "      <td>4202.56</td>\n",
       "      <td>4232.82</td>\n",
       "      <td>4209.74</td>\n",
       "      <td>4281.03</td>\n",
       "      <td>4628.21</td>\n",
       "      <td>4389.74</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         1        2        3        4        5        6        7        8  \\\n",
       "0  4324.62  4004.62  4293.85  4148.72  4342.05  4586.67  4097.44  4638.97   \n",
       "1  4327.69  4006.67  4295.38  4156.41  4336.92  4583.59  4096.92  4630.26   \n",
       "2  4328.72  4011.79  4296.41  4155.90  4343.59  4582.56  4097.44  4630.77   \n",
       "3  4326.15  4011.79  4292.31  4151.28  4347.69  4586.67  4095.90  4627.69   \n",
       "4  4321.03  4004.62  4284.10  4153.33  4345.64  4587.18  4093.33  4616.92   \n",
       "\n",
       "         9       10       11       12       13       14  Target  \n",
       "0  4210.77  4226.67  4207.69  4279.49  4632.82  4384.10       0  \n",
       "1  4207.69  4222.05  4206.67  4282.05  4628.72  4389.23       0  \n",
       "2  4217.44  4235.38  4210.77  4287.69  4632.31  4396.41       0  \n",
       "3  4210.77  4244.10  4212.82  4288.21  4632.82  4398.46       0  \n",
       "4  4202.56  4232.82  4209.74  4281.03  4628.21  4389.74       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read data from AEP hourly\n",
    "fpath='eye_state.csv'\n",
    "df=pd.read_csv(fpath, header=0, names=['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12',\n",
    "       '13', '14', 'Target'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1         0\n",
       "2         0\n",
       "3         0\n",
       "4         0\n",
       "5         0\n",
       "6         0\n",
       "7         0\n",
       "8         0\n",
       "9         0\n",
       "10        0\n",
       "11        0\n",
       "12        0\n",
       "13        0\n",
       "14        0\n",
       "Target    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check missing data in file\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1         0\n",
       "2         0\n",
       "3         0\n",
       "4         0\n",
       "5         0\n",
       "6         0\n",
       "7         0\n",
       "8         0\n",
       "9         0\n",
       "10        0\n",
       "11        0\n",
       "12        0\n",
       "13        0\n",
       "14        0\n",
       "Target    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check missing data in file\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001085</td>\n",
       "      <td>-0.112049</td>\n",
       "      <td>0.671413</td>\n",
       "      <td>-0.003111</td>\n",
       "      <td>0.008909</td>\n",
       "      <td>-0.019610</td>\n",
       "      <td>-0.002817</td>\n",
       "      <td>0.782290</td>\n",
       "      <td>-0.003771</td>\n",
       "      <td>-0.122092</td>\n",
       "      <td>0.138509</td>\n",
       "      <td>0.006194</td>\n",
       "      <td>0.014578</td>\n",
       "      <td>-0.005489</td>\n",
       "      <td>-0.902395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002316</td>\n",
       "      <td>-0.067427</td>\n",
       "      <td>0.705851</td>\n",
       "      <td>-0.001637</td>\n",
       "      <td>-0.138765</td>\n",
       "      <td>-0.020663</td>\n",
       "      <td>-0.002930</td>\n",
       "      <td>0.484938</td>\n",
       "      <td>-0.005213</td>\n",
       "      <td>-0.243509</td>\n",
       "      <td>0.111515</td>\n",
       "      <td>0.067815</td>\n",
       "      <td>0.011185</td>\n",
       "      <td>-0.004618</td>\n",
       "      <td>-0.902395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002730</td>\n",
       "      <td>0.044018</td>\n",
       "      <td>0.729035</td>\n",
       "      <td>-0.001734</td>\n",
       "      <td>0.053240</td>\n",
       "      <td>-0.021016</td>\n",
       "      <td>-0.002817</td>\n",
       "      <td>0.502349</td>\n",
       "      <td>-0.000649</td>\n",
       "      <td>0.106812</td>\n",
       "      <td>0.220021</td>\n",
       "      <td>0.203573</td>\n",
       "      <td>0.014156</td>\n",
       "      <td>-0.003399</td>\n",
       "      <td>-0.902395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001698</td>\n",
       "      <td>0.044018</td>\n",
       "      <td>0.636750</td>\n",
       "      <td>-0.002620</td>\n",
       "      <td>0.171264</td>\n",
       "      <td>-0.019610</td>\n",
       "      <td>-0.003152</td>\n",
       "      <td>0.397201</td>\n",
       "      <td>-0.003771</td>\n",
       "      <td>0.335979</td>\n",
       "      <td>0.274274</td>\n",
       "      <td>0.216090</td>\n",
       "      <td>0.014578</td>\n",
       "      <td>-0.003052</td>\n",
       "      <td>-0.902395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.000356</td>\n",
       "      <td>-0.112049</td>\n",
       "      <td>0.451955</td>\n",
       "      <td>-0.002227</td>\n",
       "      <td>0.112252</td>\n",
       "      <td>-0.019436</td>\n",
       "      <td>-0.003710</td>\n",
       "      <td>0.029522</td>\n",
       "      <td>-0.007614</td>\n",
       "      <td>0.039533</td>\n",
       "      <td>0.192762</td>\n",
       "      <td>0.043263</td>\n",
       "      <td>0.010763</td>\n",
       "      <td>-0.004532</td>\n",
       "      <td>-0.902395</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          1         2         3         4         5         6         7  \\\n",
       "0  0.001085 -0.112049  0.671413 -0.003111  0.008909 -0.019610 -0.002817   \n",
       "1  0.002316 -0.067427  0.705851 -0.001637 -0.138765 -0.020663 -0.002930   \n",
       "2  0.002730  0.044018  0.729035 -0.001734  0.053240 -0.021016 -0.002817   \n",
       "3  0.001698  0.044018  0.636750 -0.002620  0.171264 -0.019610 -0.003152   \n",
       "4 -0.000356 -0.112049  0.451955 -0.002227  0.112252 -0.019436 -0.003710   \n",
       "\n",
       "          8         9        10        11        12        13        14  \\\n",
       "0  0.782290 -0.003771 -0.122092  0.138509  0.006194  0.014578 -0.005489   \n",
       "1  0.484938 -0.005213 -0.243509  0.111515  0.067815  0.011185 -0.004618   \n",
       "2  0.502349 -0.000649  0.106812  0.220021  0.203573  0.014156 -0.003399   \n",
       "3  0.397201 -0.003771  0.335979  0.274274  0.216090  0.014578 -0.003052   \n",
       "4  0.029522 -0.007614  0.039533  0.192762  0.043263  0.010763 -0.004532   \n",
       "\n",
       "     Target  \n",
       "0 -0.902395  \n",
       "1 -0.902395  \n",
       "2 -0.902395  \n",
       "3 -0.902395  \n",
       "4 -0.902395  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalize the data\n",
    "scaler = StandardScaler() \n",
    "scaled_values = scaler.fit_transform(df) \n",
    "df.loc[:,:] = scaled_values\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Target\n",
       "0       0\n",
       "1       0\n",
       "2       0\n",
       "3       0\n",
       "4       0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prepare df for target results\n",
    "y=pd.DataFrame({'Target':df['Target']})\n",
    "y['Target']=y['Target'].astype(int)\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001085</td>\n",
       "      <td>-0.112049</td>\n",
       "      <td>0.671413</td>\n",
       "      <td>-0.003111</td>\n",
       "      <td>0.008909</td>\n",
       "      <td>-0.019610</td>\n",
       "      <td>-0.002817</td>\n",
       "      <td>0.782290</td>\n",
       "      <td>-0.003771</td>\n",
       "      <td>-0.122092</td>\n",
       "      <td>0.138509</td>\n",
       "      <td>0.006194</td>\n",
       "      <td>0.014578</td>\n",
       "      <td>-0.005489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002316</td>\n",
       "      <td>-0.067427</td>\n",
       "      <td>0.705851</td>\n",
       "      <td>-0.001637</td>\n",
       "      <td>-0.138765</td>\n",
       "      <td>-0.020663</td>\n",
       "      <td>-0.002930</td>\n",
       "      <td>0.484938</td>\n",
       "      <td>-0.005213</td>\n",
       "      <td>-0.243509</td>\n",
       "      <td>0.111515</td>\n",
       "      <td>0.067815</td>\n",
       "      <td>0.011185</td>\n",
       "      <td>-0.004618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002730</td>\n",
       "      <td>0.044018</td>\n",
       "      <td>0.729035</td>\n",
       "      <td>-0.001734</td>\n",
       "      <td>0.053240</td>\n",
       "      <td>-0.021016</td>\n",
       "      <td>-0.002817</td>\n",
       "      <td>0.502349</td>\n",
       "      <td>-0.000649</td>\n",
       "      <td>0.106812</td>\n",
       "      <td>0.220021</td>\n",
       "      <td>0.203573</td>\n",
       "      <td>0.014156</td>\n",
       "      <td>-0.003399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001698</td>\n",
       "      <td>0.044018</td>\n",
       "      <td>0.636750</td>\n",
       "      <td>-0.002620</td>\n",
       "      <td>0.171264</td>\n",
       "      <td>-0.019610</td>\n",
       "      <td>-0.003152</td>\n",
       "      <td>0.397201</td>\n",
       "      <td>-0.003771</td>\n",
       "      <td>0.335979</td>\n",
       "      <td>0.274274</td>\n",
       "      <td>0.216090</td>\n",
       "      <td>0.014578</td>\n",
       "      <td>-0.003052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.000356</td>\n",
       "      <td>-0.112049</td>\n",
       "      <td>0.451955</td>\n",
       "      <td>-0.002227</td>\n",
       "      <td>0.112252</td>\n",
       "      <td>-0.019436</td>\n",
       "      <td>-0.003710</td>\n",
       "      <td>0.029522</td>\n",
       "      <td>-0.007614</td>\n",
       "      <td>0.039533</td>\n",
       "      <td>0.192762</td>\n",
       "      <td>0.043263</td>\n",
       "      <td>0.010763</td>\n",
       "      <td>-0.004532</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          1         2         3         4         5         6         7  \\\n",
       "0  0.001085 -0.112049  0.671413 -0.003111  0.008909 -0.019610 -0.002817   \n",
       "1  0.002316 -0.067427  0.705851 -0.001637 -0.138765 -0.020663 -0.002930   \n",
       "2  0.002730  0.044018  0.729035 -0.001734  0.053240 -0.021016 -0.002817   \n",
       "3  0.001698  0.044018  0.636750 -0.002620  0.171264 -0.019610 -0.003152   \n",
       "4 -0.000356 -0.112049  0.451955 -0.002227  0.112252 -0.019436 -0.003710   \n",
       "\n",
       "          8         9        10        11        12        13        14  \n",
       "0  0.782290 -0.003771 -0.122092  0.138509  0.006194  0.014578 -0.005489  \n",
       "1  0.484938 -0.005213 -0.243509  0.111515  0.067815  0.011185 -0.004618  \n",
       "2  0.502349 -0.000649  0.106812  0.220021  0.203573  0.014156 -0.003399  \n",
       "3  0.397201 -0.003771  0.335979  0.274274  0.216090  0.014578 -0.003052  \n",
       "4  0.029522 -0.007614  0.039533  0.192762  0.043263  0.010763 -0.004532  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove results from the input df\n",
    "df = df.drop(columns=['Target'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape  (14979, 14)\n",
      "Train data shapes  (10485, 14) ,  (10485, 1)\n",
      "Test data shapes  (4494, 14) ,  (4494, 1)\n"
     ]
    }
   ],
   "source": [
    "# change input format from df to array\n",
    "df=np.array(df)\n",
    "y=np.array(y)\n",
    "\n",
    "# split the data into test and train\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, y, test_size=0.3)\n",
    "print(\"Input shape \", df.shape)\n",
    "print(\"Train data shapes \", X_train.shape,\", \", y_train.shape) \n",
    "print(\"Test data shapes \", X_test.shape,\", \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape  (14979, 14)\n",
      "Train data shapes  (10485, 14, 1) ,  (10485, 1)\n",
      "Test data shapes  (4494, 14, 1) ,  (4494, 1)\n"
     ]
    }
   ],
   "source": [
    "# change input dimensions to 3 for LSTM input\n",
    "X_train = np.reshape(X_train, (10485, 14, 1))\n",
    "X_test = np.reshape(X_test, (4494, 14, 1))\n",
    "print(\"Input shape \", df.shape)\n",
    "print(\"Train data shapes \", X_train.shape,\", \", y_train.shape) \n",
    "print(\"Test data shapes \", X_test.shape,\", \", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result(model, X_test, y_test, model_name=\"Test\"): \n",
    "    print(f\"Model - {model_name}:\")\n",
    "    \n",
    "    predictions = model.predict(X_test)\n",
    "    y_test=y_test.astype('int32')\n",
    "    acc=accuracy_score(y_test, (predictions> 0.5).astype(int))\n",
    "    print(\"Accuracy Score:\",acc)\n",
    "    return model.predict(X_test)\n",
    "\n",
    "def plot_predictions(test, predicted, title=\"Test\", xLabel=\"Test\", yLabel=\"Test\", realLabel=\"Test\", predictedLabel=\"Test\"):\n",
    "    plt.figure(figsize=(20,8))\n",
    "    plt.rcParams.update({'font.size': 18})\n",
    "    plt.plot(test, color='red',label=realLabel)\n",
    "    plt.plot(predicted, alpha=0.7, color='blue',label=predictedLabel)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xLabel)\n",
    "    plt.ylabel(yLabel)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n_hidden_first = 50n_hidden_first = 50### Models in Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden_first = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm(X_train,y_train):\n",
    "    lstm_model = Sequential()\n",
    "\n",
    "    lstm_model.add(LSTM(128, input_shape=(X_train.shape[1], 1)))\n",
    "    lstm_model.add(Dropout(0.15))\n",
    "    lstm_model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "    lstm_model.summary()\n",
    "    adam_modified = optimizers.Adam(learning_rate=0.005, beta_1=0.7, beta_2=0.9, amsgrad=False)\n",
    "    # train LSTM model\n",
    "    lstm_model.compile(loss=\"binary_crossentropy\", optimizer=adam_modified, metrics=[\"accuracy\"])\n",
    "    lstm_model.fit(X_train, y_train, epochs=40)\n",
    "    return lstm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stacked_lstm(X_train,y_train):\n",
    "# build Stacked_LSTM model\n",
    "    s_lstm_model = Sequential()\n",
    "\n",
    "    s_lstm_model.add(LSTM(n_hidden_first,return_sequences=True,activation=\"tanh\", input_shape=(X_train.shape[1],1)))\n",
    "    s_lstm_model.add(Dropout(0.15))\n",
    "    s_lstm_model.add(LSTM(128, return_sequences=False))\n",
    "    s_lstm_model.add(Dropout(0.2))\n",
    "    s_lstm_model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "    s_lstm_model.summary()\n",
    "    adam_modified = optimizers.Adam(learning_rate=0.005, beta_1=0.7, beta_2=0.9, amsgrad=False)\n",
    "    # train LSTM model\n",
    "    s_lstm_model.compile(loss=\"binary_crossentropy\", optimizer=adam_modified, metrics=[\"accuracy\"])\n",
    "    s_lstm_model.fit(X_train, y_train, epochs=40)\n",
    "    return s_lstm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gru(X_train,y_train):\n",
    "    # build GRU model\n",
    "    gru_model = Sequential()\n",
    "\n",
    "    gru_model.add(GRU(n_hidden_first,activation=\"tanh\", input_shape=(X_train.shape[1],1)))\n",
    "    gru_model.add(Dropout(0.15))\n",
    "\n",
    "    gru_model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "    gru_model.summary()\n",
    "    adam_modified = optimizers.Adam(learning_rate=0.005, beta_1=0.7, beta_2=0.9, amsgrad=False)\n",
    "    # train LSTM model\n",
    "    gru_model.compile(loss=\"binary_crossentropy\", optimizer=adam_modified, metrics=[\"accuracy\"])\n",
    "    gru_model.fit(X_train, y_train, epochs=40)\n",
    "    return gru_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn(X_train,y_train):\n",
    "    rnn_model = Sequential()\n",
    "\n",
    "    rnn_model.add(SimpleRNN(n_hidden_first,activation=\"relu\", return_sequences=True, input_shape=(X_train.shape[1],1)))\n",
    "    rnn_model.add(Dropout(0.15))\n",
    "    rnn_model.add(LSTM(10, return_sequences=False))\n",
    "    rnn_model.add(Dropout(0.2))\n",
    "    rnn_model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "    rnn_model.summary()\n",
    "    adam_modified = optimizers.Adam(learning_rate=0.005, beta_1=0.7, beta_2=0.9, amsgrad=False)\n",
    "    # train LSTM model\n",
    "    rnn_model.compile(loss=\"binary_crossentropy\", optimizer=adam_modified, metrics=[\"accuracy\"])\n",
    "    rnn_model.fit(X_train, y_train, epochs=30)\n",
    "\n",
    "    return rnn_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn(X_train,y_train):\n",
    "    cnn_model = Sequential()\n",
    "    cnn_model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_train.shape[1],1)))\n",
    "    cnn_model.add(MaxPooling1D(pool_size=3))\n",
    "    cnn_model.add(Flatten())\n",
    "    cnn_model.add(Dense(30, activation='relu'))\n",
    "    cnn_model.add(Dense(10, activation='relu'))\n",
    "    cnn_model.add(Dense(1))\n",
    "    cnn_model.summary()\n",
    "    cnn_model.compile(optimizer=\"adam\",loss=\"MSE\")\n",
    "    cnn_model.fit(X_train, y_train, epochs=50)\n",
    "    return cnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_lstm(X_train,y_train):\n",
    "    n_seq = 1\n",
    "    X_train_reshaped = X_train.reshape((X_train.shape[0], n_seq, X_train.shape[1], 1))\n",
    "\n",
    "    cnn_lstm_model = Sequential()\n",
    "    cnn_lstm_model.add(TimeDistributed(Conv1D(filters=64, kernel_size=2, activation='relu'), input_shape=(None, X_train.shape[1],1)))\n",
    "    cnn_lstm_model.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n",
    "    cnn_lstm_model.add(TimeDistributed(Flatten()))\n",
    "    cnn_lstm_model.add(LSTM(15, activation='relu'))\n",
    "    cnn_lstm_model.add(Dense(1))\n",
    "\n",
    "    cnn_lstm_model.summary() \n",
    "    cnn_lstm_model.compile(optimizer=\"adam\",loss=\"MSE\")\n",
    "    cnn_lstm_model.fit(X_train_reshaped, y_train, epochs=50)\n",
    "    return cnn_lstm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convlstm(X_train,y_train):\n",
    "    n_seq = 1\n",
    "    n_features = 1\n",
    "    X_train_reshaped = X_train.reshape((X_train.shape[0], n_seq, 1, X_train.shape[1], n_features))\n",
    "\n",
    "    conv_lstm_model = Sequential()\n",
    "    conv_lstm_model.add(ConvLSTM2D(filters=64, kernel_size=(1,2), activation='relu', input_shape=(n_seq, 1, X_train.shape[1], n_features)))\n",
    "    conv_lstm_model.add(Flatten())\n",
    "    conv_lstm_model.add(Dense(20, activation='relu'))\n",
    "    conv_lstm_model.add(Dense(10, activation='relu'))\n",
    "    conv_lstm_model.add(Dense(1)) \n",
    "    conv_lstm_model.summary()\n",
    "\n",
    "    conv_lstm_model.compile(optimizer=\"adam\",loss=\"MSE\")\n",
    "    conv_lstm_model.fit(X_train_reshaped, y_train, epochs=50)\n",
    "    return conv_lstm_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and fitting models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 128)               66560     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,689\n",
      "Trainable params: 66,689\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "328/328 [==============================] - 4s 8ms/step - loss: 0.6785 - accuracy: 0.5646\n",
      "Epoch 2/40\n",
      "328/328 [==============================] - 3s 8ms/step - loss: 0.6658 - accuracy: 0.5940\n",
      "Epoch 3/40\n",
      "328/328 [==============================] - 3s 8ms/step - loss: 0.6420 - accuracy: 0.6260\n",
      "Epoch 4/40\n",
      "328/328 [==============================] - 3s 8ms/step - loss: 0.6177 - accuracy: 0.6512\n",
      "Epoch 5/40\n",
      "328/328 [==============================] - 3s 8ms/step - loss: 0.5905 - accuracy: 0.6787\n",
      "Epoch 6/40\n",
      "328/328 [==============================] - 3s 8ms/step - loss: 0.5617 - accuracy: 0.7041\n",
      "Epoch 7/40\n",
      "328/328 [==============================] - 2s 8ms/step - loss: 0.5276 - accuracy: 0.7288\n",
      "Epoch 8/40\n",
      "328/328 [==============================] - 3s 8ms/step - loss: 0.5023 - accuracy: 0.7424\n",
      "Epoch 9/40\n",
      "328/328 [==============================] - 3s 8ms/step - loss: 0.4765 - accuracy: 0.7683\n",
      "Epoch 10/40\n",
      "328/328 [==============================] - 3s 9ms/step - loss: 0.4591 - accuracy: 0.7742\n",
      "Epoch 11/40\n",
      "328/328 [==============================] - 3s 8ms/step - loss: 0.4372 - accuracy: 0.7844\n",
      "Epoch 12/40\n",
      "328/328 [==============================] - 3s 8ms/step - loss: 0.4302 - accuracy: 0.7929\n",
      "Epoch 13/40\n",
      "328/328 [==============================] - 3s 8ms/step - loss: 0.4162 - accuracy: 0.7987\n",
      "Epoch 14/40\n",
      "328/328 [==============================] - 3s 8ms/step - loss: 0.4031 - accuracy: 0.8076\n",
      "Epoch 15/40\n",
      "328/328 [==============================] - 3s 8ms/step - loss: 0.3953 - accuracy: 0.8130\n",
      "Epoch 16/40\n",
      "328/328 [==============================] - 2s 7ms/step - loss: 0.3839 - accuracy: 0.8212\n",
      "Epoch 17/40\n",
      "328/328 [==============================] - 2s 8ms/step - loss: 0.3728 - accuracy: 0.8285\n",
      "Epoch 18/40\n",
      "328/328 [==============================] - 2s 8ms/step - loss: 0.3630 - accuracy: 0.8312\n",
      "Epoch 19/40\n",
      "328/328 [==============================] - 3s 9ms/step - loss: 0.3500 - accuracy: 0.8357\n",
      "Epoch 20/40\n",
      "328/328 [==============================] - 3s 9ms/step - loss: 0.3450 - accuracy: 0.8398\n",
      "Epoch 21/40\n",
      "328/328 [==============================] - 3s 8ms/step - loss: 0.3342 - accuracy: 0.8455\n",
      "Epoch 22/40\n",
      "328/328 [==============================] - 3s 8ms/step - loss: 0.3265 - accuracy: 0.8462\n",
      "Epoch 23/40\n",
      "328/328 [==============================] - 3s 8ms/step - loss: 0.3238 - accuracy: 0.8546\n",
      "Epoch 24/40\n",
      "328/328 [==============================] - 3s 8ms/step - loss: 0.3125 - accuracy: 0.8559\n",
      "Epoch 25/40\n",
      "328/328 [==============================] - 2s 8ms/step - loss: 0.2992 - accuracy: 0.8591\n",
      "Epoch 26/40\n",
      "328/328 [==============================] - 3s 8ms/step - loss: 0.2958 - accuracy: 0.8672\n",
      "Epoch 27/40\n",
      "328/328 [==============================] - 3s 8ms/step - loss: 0.2858 - accuracy: 0.8668\n",
      "Epoch 28/40\n",
      "328/328 [==============================] - 3s 8ms/step - loss: 0.2792 - accuracy: 0.8711\n",
      "Epoch 29/40\n",
      "328/328 [==============================] - 2s 8ms/step - loss: 0.2718 - accuracy: 0.8766\n",
      "Epoch 30/40\n",
      "328/328 [==============================] - 3s 8ms/step - loss: 0.2620 - accuracy: 0.8814\n",
      "Epoch 31/40\n",
      "328/328 [==============================] - 3s 8ms/step - loss: 0.2557 - accuracy: 0.8849\n",
      "Epoch 32/40\n",
      "328/328 [==============================] - 3s 9ms/step - loss: 0.2493 - accuracy: 0.8897\n",
      "Epoch 33/40\n",
      "328/328 [==============================] - 3s 10ms/step - loss: 0.2390 - accuracy: 0.8955\n",
      "Epoch 34/40\n",
      "328/328 [==============================] - 3s 10ms/step - loss: 0.2338 - accuracy: 0.8973\n",
      "Epoch 35/40\n",
      "328/328 [==============================] - 3s 10ms/step - loss: 0.2235 - accuracy: 0.9013\n",
      "Epoch 36/40\n",
      "328/328 [==============================] - 3s 8ms/step - loss: 0.2175 - accuracy: 0.9042\n",
      "Epoch 37/40\n",
      "328/328 [==============================] - 2s 7ms/step - loss: 0.2131 - accuracy: 0.9054\n",
      "Epoch 38/40\n",
      "328/328 [==============================] - 3s 8ms/step - loss: 0.2003 - accuracy: 0.9140\n",
      "Epoch 39/40\n",
      "328/328 [==============================] - 2s 8ms/step - loss: 0.2006 - accuracy: 0.9163\n",
      "Epoch 40/40\n",
      "328/328 [==============================] - 2s 8ms/step - loss: 0.1969 - accuracy: 0.9169\n",
      "Model - LSTM:\n",
      "Accuracy Score: 0.8246550956831331\n"
     ]
    }
   ],
   "source": [
    "# build LSTM model\n",
    "lstm_model=lstm(X_train,y_train)\n",
    "lstm_predictions = get_result(lstm_model, X_test, y_test, \"LSTM\")\n",
    "#plot_predictions(y_test, lstm_predictions, \"LSTM model\", xLabel=\"Time\", yLabel=\"Power Consumption\", realLabel=\"Actual power consumption\", predictedLabel=\"Predicted power consumption\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_1 (LSTM)               (None, 14, 50)            10400     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 14, 50)            0         \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 128)               91648     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 102,177\n",
      "Trainable params: 102,177\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "328/328 [==============================] - 7s 11ms/step - loss: 0.6797 - accuracy: 0.5704\n",
      "Epoch 2/40\n",
      "328/328 [==============================] - 4s 12ms/step - loss: 0.6653 - accuracy: 0.5885\n",
      "Epoch 3/40\n",
      "328/328 [==============================] - 4s 13ms/step - loss: 0.6520 - accuracy: 0.6080\n",
      "Epoch 4/40\n",
      "328/328 [==============================] - 4s 13ms/step - loss: 0.6202 - accuracy: 0.6538\n",
      "Epoch 5/40\n",
      "328/328 [==============================] - 4s 11ms/step - loss: 0.5886 - accuracy: 0.6798\n",
      "Epoch 6/40\n",
      "328/328 [==============================] - 4s 11ms/step - loss: 0.5642 - accuracy: 0.6959\n",
      "Epoch 7/40\n",
      "328/328 [==============================] - 4s 11ms/step - loss: 0.5292 - accuracy: 0.7292\n",
      "Epoch 8/40\n",
      "328/328 [==============================] - 4s 11ms/step - loss: 0.5056 - accuracy: 0.7456\n",
      "Epoch 9/40\n",
      "328/328 [==============================] - 4s 11ms/step - loss: 0.4777 - accuracy: 0.7593\n",
      "Epoch 10/40\n",
      "328/328 [==============================] - 4s 11ms/step - loss: 0.4513 - accuracy: 0.7770\n",
      "Epoch 11/40\n",
      "328/328 [==============================] - 4s 11ms/step - loss: 0.4302 - accuracy: 0.7914\n",
      "Epoch 12/40\n",
      "328/328 [==============================] - 4s 11ms/step - loss: 0.4100 - accuracy: 0.8045\n",
      "Epoch 13/40\n",
      "328/328 [==============================] - 4s 12ms/step - loss: 0.3963 - accuracy: 0.8158\n",
      "Epoch 14/40\n",
      "328/328 [==============================] - 4s 12ms/step - loss: 0.3841 - accuracy: 0.8219\n",
      "Epoch 15/40\n",
      "328/328 [==============================] - 4s 12ms/step - loss: 0.3685 - accuracy: 0.8281\n",
      "Epoch 16/40\n",
      "328/328 [==============================] - 4s 11ms/step - loss: 0.3605 - accuracy: 0.8303\n",
      "Epoch 17/40\n",
      "328/328 [==============================] - 4s 11ms/step - loss: 0.3460 - accuracy: 0.8386\n",
      "Epoch 18/40\n",
      "328/328 [==============================] - 4s 12ms/step - loss: 0.3404 - accuracy: 0.8425\n",
      "Epoch 19/40\n",
      "328/328 [==============================] - 4s 11ms/step - loss: 0.3228 - accuracy: 0.8497\n",
      "Epoch 20/40\n",
      "328/328 [==============================] - 4s 11ms/step - loss: 0.3148 - accuracy: 0.8591\n",
      "Epoch 21/40\n",
      "328/328 [==============================] - 4s 11ms/step - loss: 0.3068 - accuracy: 0.8598\n",
      "Epoch 22/40\n",
      "328/328 [==============================] - 4s 11ms/step - loss: 0.2976 - accuracy: 0.8675\n",
      "Epoch 23/40\n",
      "328/328 [==============================] - 4s 11ms/step - loss: 0.2881 - accuracy: 0.8700\n",
      "Epoch 24/40\n",
      "328/328 [==============================] - 4s 11ms/step - loss: 0.2799 - accuracy: 0.8743\n",
      "Epoch 25/40\n",
      "328/328 [==============================] - 4s 12ms/step - loss: 0.2697 - accuracy: 0.8795\n",
      "Epoch 26/40\n",
      "328/328 [==============================] - 4s 11ms/step - loss: 0.2663 - accuracy: 0.8840\n",
      "Epoch 27/40\n",
      "328/328 [==============================] - 4s 11ms/step - loss: 0.2508 - accuracy: 0.8878\n",
      "Epoch 28/40\n",
      "328/328 [==============================] - 4s 11ms/step - loss: 0.2469 - accuracy: 0.8920\n",
      "Epoch 29/40\n",
      "328/328 [==============================] - 4s 11ms/step - loss: 0.2353 - accuracy: 0.8938\n",
      "Epoch 30/40\n",
      "328/328 [==============================] - 4s 11ms/step - loss: 0.2280 - accuracy: 0.9009\n",
      "Epoch 31/40\n",
      "328/328 [==============================] - 4s 12ms/step - loss: 0.2253 - accuracy: 0.9028\n",
      "Epoch 32/40\n",
      "328/328 [==============================] - 4s 12ms/step - loss: 0.2154 - accuracy: 0.9047\n",
      "Epoch 33/40\n",
      "328/328 [==============================] - 4s 11ms/step - loss: 0.2077 - accuracy: 0.9118\n",
      "Epoch 34/40\n",
      "328/328 [==============================] - 4s 11ms/step - loss: 0.2109 - accuracy: 0.9132\n",
      "Epoch 35/40\n",
      "328/328 [==============================] - 4s 12ms/step - loss: 0.1967 - accuracy: 0.9155\n",
      "Epoch 36/40\n",
      "328/328 [==============================] - 4s 11ms/step - loss: 0.1941 - accuracy: 0.9167\n",
      "Epoch 37/40\n",
      "328/328 [==============================] - 4s 12ms/step - loss: 0.1871 - accuracy: 0.9232\n",
      "Epoch 38/40\n",
      "328/328 [==============================] - 4s 11ms/step - loss: 0.1799 - accuracy: 0.9246\n",
      "Epoch 39/40\n",
      "328/328 [==============================] - 4s 12ms/step - loss: 0.1735 - accuracy: 0.9283\n",
      "Epoch 40/40\n",
      "328/328 [==============================] - 4s 11ms/step - loss: 0.1796 - accuracy: 0.9250\n",
      "Model - Stacked LSTM:\n",
      "Accuracy Score: 0.8215398308856253\n"
     ]
    }
   ],
   "source": [
    "# build Stacked_LSTM model\n",
    "s_lstm_model = stacked_lstm(X_train,y_train)\n",
    "s_lstm_predictions = get_result(s_lstm_model, X_test, y_test, \"Stacked LSTM\")\n",
    "#plot_predictions(y_test, s_lstm_predictions, \"Stacked LSTM model\", xLabel=\"Time\", yLabel=\"Power Consumption\", realLabel=\"Actual power consumption\", predictedLabel=\"Predicted power consumption\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_1 (GRU)                 (None, 50)                7950      \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 50)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,001\n",
      "Trainable params: 8,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "328/328 [==============================] - 3s 5ms/step - loss: 0.6761 - accuracy: 0.5698\n",
      "Epoch 2/40\n",
      "328/328 [==============================] - 2s 5ms/step - loss: 0.6629 - accuracy: 0.5849\n",
      "Epoch 3/40\n",
      "328/328 [==============================] - 2s 5ms/step - loss: 0.6422 - accuracy: 0.6208\n",
      "Epoch 4/40\n",
      "328/328 [==============================] - 2s 5ms/step - loss: 0.6186 - accuracy: 0.6474\n",
      "Epoch 5/40\n",
      "328/328 [==============================] - 2s 5ms/step - loss: 0.5897 - accuracy: 0.6722\n",
      "Epoch 6/40\n",
      "328/328 [==============================] - 2s 5ms/step - loss: 0.5673 - accuracy: 0.6903\n",
      "Epoch 7/40\n",
      "328/328 [==============================] - 2s 5ms/step - loss: 0.5511 - accuracy: 0.7018\n",
      "Epoch 8/40\n",
      "328/328 [==============================] - 1s 5ms/step - loss: 0.5324 - accuracy: 0.7178\n",
      "Epoch 9/40\n",
      "328/328 [==============================] - 1s 5ms/step - loss: 0.5131 - accuracy: 0.7333\n",
      "Epoch 10/40\n",
      "328/328 [==============================] - 2s 5ms/step - loss: 0.4965 - accuracy: 0.7453\n",
      "Epoch 11/40\n",
      "328/328 [==============================] - 2s 5ms/step - loss: 0.4831 - accuracy: 0.7535\n",
      "Epoch 12/40\n",
      "328/328 [==============================] - 1s 5ms/step - loss: 0.4640 - accuracy: 0.7706\n",
      "Epoch 13/40\n",
      "328/328 [==============================] - 2s 5ms/step - loss: 0.4516 - accuracy: 0.7785\n",
      "Epoch 14/40\n",
      "328/328 [==============================] - 2s 5ms/step - loss: 0.4367 - accuracy: 0.7887\n",
      "Epoch 15/40\n",
      "328/328 [==============================] - 2s 5ms/step - loss: 0.4264 - accuracy: 0.7912\n",
      "Epoch 16/40\n",
      "328/328 [==============================] - 1s 5ms/step - loss: 0.4160 - accuracy: 0.7961\n",
      "Epoch 17/40\n",
      "328/328 [==============================] - 1s 5ms/step - loss: 0.4116 - accuracy: 0.7963\n",
      "Epoch 18/40\n",
      "328/328 [==============================] - 2s 5ms/step - loss: 0.3994 - accuracy: 0.8084\n",
      "Epoch 19/40\n",
      "328/328 [==============================] - 2s 5ms/step - loss: 0.3939 - accuracy: 0.8152\n",
      "Epoch 20/40\n",
      "328/328 [==============================] - 2s 5ms/step - loss: 0.3837 - accuracy: 0.8174\n",
      "Epoch 21/40\n",
      "328/328 [==============================] - 2s 5ms/step - loss: 0.3762 - accuracy: 0.8197\n",
      "Epoch 22/40\n",
      "328/328 [==============================] - 2s 5ms/step - loss: 0.3732 - accuracy: 0.8217\n",
      "Epoch 23/40\n",
      "328/328 [==============================] - 2s 5ms/step - loss: 0.3670 - accuracy: 0.8278\n",
      "Epoch 24/40\n",
      "328/328 [==============================] - 1s 5ms/step - loss: 0.3588 - accuracy: 0.8340\n",
      "Epoch 25/40\n",
      "328/328 [==============================] - 1s 4ms/step - loss: 0.3580 - accuracy: 0.8340\n",
      "Epoch 26/40\n",
      "328/328 [==============================] - 1s 5ms/step - loss: 0.3528 - accuracy: 0.8337\n",
      "Epoch 27/40\n",
      "328/328 [==============================] - 2s 5ms/step - loss: 0.3458 - accuracy: 0.8404\n",
      "Epoch 28/40\n",
      "328/328 [==============================] - 2s 5ms/step - loss: 0.3426 - accuracy: 0.8424\n",
      "Epoch 29/40\n",
      "328/328 [==============================] - 2s 5ms/step - loss: 0.3408 - accuracy: 0.8405\n",
      "Epoch 30/40\n",
      "328/328 [==============================] - 2s 5ms/step - loss: 0.3340 - accuracy: 0.8448\n",
      "Epoch 31/40\n",
      "328/328 [==============================] - 2s 5ms/step - loss: 0.3305 - accuracy: 0.8484\n",
      "Epoch 32/40\n",
      "328/328 [==============================] - 2s 5ms/step - loss: 0.3310 - accuracy: 0.8494\n",
      "Epoch 33/40\n",
      "328/328 [==============================] - 1s 5ms/step - loss: 0.3208 - accuracy: 0.8525\n",
      "Epoch 34/40\n",
      "328/328 [==============================] - 2s 5ms/step - loss: 0.3176 - accuracy: 0.8547\n",
      "Epoch 35/40\n",
      "328/328 [==============================] - 2s 5ms/step - loss: 0.3124 - accuracy: 0.8546\n",
      "Epoch 36/40\n",
      "328/328 [==============================] - 2s 5ms/step - loss: 0.3114 - accuracy: 0.8569\n",
      "Epoch 37/40\n",
      "328/328 [==============================] - 2s 5ms/step - loss: 0.3095 - accuracy: 0.8602\n",
      "Epoch 38/40\n",
      "328/328 [==============================] - 1s 5ms/step - loss: 0.3095 - accuracy: 0.8598\n",
      "Epoch 39/40\n",
      "328/328 [==============================] - 2s 5ms/step - loss: 0.3038 - accuracy: 0.8634\n",
      "Epoch 40/40\n",
      "328/328 [==============================] - 2s 5ms/step - loss: 0.2943 - accuracy: 0.8648\n",
      "Model - GRU:\n",
      "Accuracy Score: 0.810636404094348\n"
     ]
    }
   ],
   "source": [
    "gru_model=gru(X_train,y_train)\n",
    "gru_predictions = get_result(gru_model, X_test, y_test, \"GRU\")\n",
    "#plot_predictions(y_test, gru_predictions, \"GRU model\", xLabel=\"Time\", yLabel=\"Power Consumption\", realLabel=\"Actual power consumption\", predictedLabel=\"Predicted power consumption\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-24 00:29:05.308326: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-04-24 00:29:05.308373: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (galib-HP-ENVY-Notebook): /proc/driver/nvidia/version does not exist\n",
      "2022-04-24 00:29:05.308903: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn (SimpleRNN)      (None, 14, 50)            2600      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 14, 50)            0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 10)                2440      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 10)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,051\n",
      "Trainable params: 5,051\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "328/328 [==============================] - 5s 9ms/step - loss: 0.6652 - accuracy: 0.5821\n",
      "Epoch 2/30\n",
      "328/328 [==============================] - 2s 7ms/step - loss: 0.6254 - accuracy: 0.6359\n",
      "Epoch 3/30\n",
      "328/328 [==============================] - 2s 7ms/step - loss: 0.5947 - accuracy: 0.6676\n",
      "Epoch 4/30\n",
      "328/328 [==============================] - 2s 7ms/step - loss: 0.5783 - accuracy: 0.6820\n",
      "Epoch 5/30\n",
      "328/328 [==============================] - 2s 7ms/step - loss: 0.5685 - accuracy: 0.6914\n",
      "Epoch 6/30\n",
      "328/328 [==============================] - 2s 7ms/step - loss: 0.5661 - accuracy: 0.6995\n",
      "Epoch 7/30\n",
      "328/328 [==============================] - 2s 7ms/step - loss: 0.5495 - accuracy: 0.7051\n",
      "Epoch 8/30\n",
      "328/328 [==============================] - 2s 6ms/step - loss: 0.5410 - accuracy: 0.7138\n",
      "Epoch 9/30\n",
      "328/328 [==============================] - 2s 6ms/step - loss: 0.5331 - accuracy: 0.7168\n",
      "Epoch 10/30\n",
      "328/328 [==============================] - 2s 7ms/step - loss: 0.5302 - accuracy: 0.7211\n",
      "Epoch 11/30\n",
      "328/328 [==============================] - 3s 9ms/step - loss: 0.5288 - accuracy: 0.7270\n",
      "Epoch 12/30\n",
      "328/328 [==============================] - 4s 13ms/step - loss: 0.5293 - accuracy: 0.7248\n",
      "Epoch 13/30\n",
      "328/328 [==============================] - 6s 17ms/step - loss: 0.5266 - accuracy: 0.7297\n",
      "Epoch 14/30\n",
      "328/328 [==============================] - 3s 8ms/step - loss: 0.5280 - accuracy: 0.7224\n",
      "Epoch 15/30\n",
      "328/328 [==============================] - 3s 8ms/step - loss: 0.5204 - accuracy: 0.7364\n",
      "Epoch 16/30\n",
      "328/328 [==============================] - 3s 8ms/step - loss: 0.5221 - accuracy: 0.7351\n",
      "Epoch 17/30\n",
      "328/328 [==============================] - 2s 7ms/step - loss: 0.5318 - accuracy: 0.7216\n",
      "Epoch 18/30\n",
      "328/328 [==============================] - 2s 7ms/step - loss: 0.5380 - accuracy: 0.7197\n",
      "Epoch 19/30\n",
      "328/328 [==============================] - 2s 7ms/step - loss: 0.5496 - accuracy: 0.7180\n",
      "Epoch 20/30\n",
      "328/328 [==============================] - 2s 7ms/step - loss: 0.5353 - accuracy: 0.7234\n",
      "Epoch 21/30\n",
      "328/328 [==============================] - 4s 11ms/step - loss: 0.5260 - accuracy: 0.7256\n",
      "Epoch 22/30\n",
      "328/328 [==============================] - 2s 7ms/step - loss: 0.5321 - accuracy: 0.7260\n",
      "Epoch 23/30\n",
      "328/328 [==============================] - 2s 7ms/step - loss: 0.5205 - accuracy: 0.7343\n",
      "Epoch 24/30\n",
      "328/328 [==============================] - 4s 12ms/step - loss: 0.5299 - accuracy: 0.7302\n",
      "Epoch 25/30\n",
      "328/328 [==============================] - 4s 11ms/step - loss: 0.5236 - accuracy: 0.7313\n",
      "Epoch 26/30\n",
      "328/328 [==============================] - 4s 13ms/step - loss: 0.5234 - accuracy: 0.7319\n",
      "Epoch 27/30\n",
      "328/328 [==============================] - 3s 10ms/step - loss: 0.5338 - accuracy: 0.7248\n",
      "Epoch 28/30\n",
      "328/328 [==============================] - 3s 9ms/step - loss: 0.5286 - accuracy: 0.7247\n",
      "Epoch 29/30\n",
      "328/328 [==============================] - 3s 10ms/step - loss: 0.5397 - accuracy: 0.7204\n",
      "Epoch 30/30\n",
      "328/328 [==============================] - 3s 10ms/step - loss: 0.5184 - accuracy: 0.7389\n",
      "Model - RNN:\n",
      "Accuracy Score: 0.742545616377392\n"
     ]
    }
   ],
   "source": [
    "# build RNN model\n",
    "rnn_model=rnn(X_train,y_train)\n",
    "rnn_predictions = get_result(rnn_model, X_test, y_test, \"RNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 12, 64)            256       \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 4, 64)            0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 30)                7710      \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 10)                310       \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,287\n",
      "Trainable params: 8,287\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "328/328 [==============================] - 1s 1ms/step - loss: 0.4033\n",
      "Epoch 2/50\n",
      "328/328 [==============================] - 0s 1ms/step - loss: 0.2607\n",
      "Epoch 3/50\n",
      "328/328 [==============================] - 0s 2ms/step - loss: 0.2285\n",
      "Epoch 4/50\n",
      "328/328 [==============================] - 0s 1ms/step - loss: 0.2570\n",
      "Epoch 5/50\n",
      "328/328 [==============================] - 1s 2ms/step - loss: 0.3190\n",
      "Epoch 6/50\n",
      "328/328 [==============================] - 1s 2ms/step - loss: 0.2632\n",
      "Epoch 7/50\n",
      "328/328 [==============================] - 0s 1ms/step - loss: 0.2278\n",
      "Epoch 8/50\n",
      "328/328 [==============================] - 0s 1ms/step - loss: 0.2209\n",
      "Epoch 9/50\n",
      "328/328 [==============================] - 0s 1ms/step - loss: 0.2181\n",
      "Epoch 10/50\n",
      "328/328 [==============================] - 0s 1ms/step - loss: 0.2185\n",
      "Epoch 11/50\n",
      "328/328 [==============================] - 0s 2ms/step - loss: 0.2401\n",
      "Epoch 12/50\n",
      "328/328 [==============================] - 1s 2ms/step - loss: 0.2141\n",
      "Epoch 13/50\n",
      "328/328 [==============================] - 0s 1ms/step - loss: 0.2132\n",
      "Epoch 14/50\n",
      "328/328 [==============================] - 0s 2ms/step - loss: 0.2096\n",
      "Epoch 15/50\n",
      "328/328 [==============================] - 1s 2ms/step - loss: 0.2067\n",
      "Epoch 16/50\n",
      "328/328 [==============================] - 0s 1ms/step - loss: 0.2021\n",
      "Epoch 17/50\n",
      "328/328 [==============================] - 0s 1ms/step - loss: 0.2177\n",
      "Epoch 18/50\n",
      "328/328 [==============================] - 0s 1ms/step - loss: 0.2507\n",
      "Epoch 19/50\n",
      "328/328 [==============================] - 0s 1ms/step - loss: 0.1974\n",
      "Epoch 20/50\n",
      "328/328 [==============================] - 0s 1ms/step - loss: 0.1935\n",
      "Epoch 21/50\n",
      "328/328 [==============================] - 0s 1ms/step - loss: 0.1909\n",
      "Epoch 22/50\n",
      "328/328 [==============================] - 0s 1ms/step - loss: 0.1866\n",
      "Epoch 23/50\n",
      "328/328 [==============================] - 0s 1ms/step - loss: 0.1905\n",
      "Epoch 24/50\n",
      "328/328 [==============================] - 0s 1ms/step - loss: 0.1843\n",
      "Epoch 25/50\n",
      "328/328 [==============================] - 0s 1ms/step - loss: 0.1787\n",
      "Epoch 26/50\n",
      "328/328 [==============================] - 0s 1ms/step - loss: 0.1780\n",
      "Epoch 27/50\n",
      "328/328 [==============================] - 1s 2ms/step - loss: 0.1727\n",
      "Epoch 28/50\n",
      "328/328 [==============================] - 1s 2ms/step - loss: 0.1705\n",
      "Epoch 29/50\n",
      "328/328 [==============================] - 1s 2ms/step - loss: 0.1681\n",
      "Epoch 30/50\n",
      "328/328 [==============================] - 0s 1ms/step - loss: 0.1667\n",
      "Epoch 31/50\n",
      "328/328 [==============================] - 0s 1ms/step - loss: 0.1647\n",
      "Epoch 32/50\n",
      "328/328 [==============================] - 0s 1ms/step - loss: 0.1633\n",
      "Epoch 33/50\n",
      "328/328 [==============================] - 1s 2ms/step - loss: 0.1619\n",
      "Epoch 34/50\n",
      "328/328 [==============================] - 1s 2ms/step - loss: 0.1608\n",
      "Epoch 35/50\n",
      "328/328 [==============================] - 0s 1ms/step - loss: 0.1594\n",
      "Epoch 36/50\n",
      "328/328 [==============================] - 0s 1ms/step - loss: 0.1611\n",
      "Epoch 37/50\n",
      "328/328 [==============================] - 0s 1ms/step - loss: 0.1634\n",
      "Epoch 38/50\n",
      "328/328 [==============================] - 0s 1ms/step - loss: 0.1581\n",
      "Epoch 39/50\n",
      "328/328 [==============================] - 0s 1ms/step - loss: 0.1561\n",
      "Epoch 40/50\n",
      "328/328 [==============================] - 0s 1ms/step - loss: 0.1544\n",
      "Epoch 41/50\n",
      "328/328 [==============================] - 0s 1ms/step - loss: 0.1544\n",
      "Epoch 42/50\n",
      "328/328 [==============================] - 1s 2ms/step - loss: 0.1524\n",
      "Epoch 43/50\n",
      "328/328 [==============================] - 0s 1ms/step - loss: 0.1738\n",
      "Epoch 44/50\n",
      "328/328 [==============================] - 0s 1ms/step - loss: 0.1589\n",
      "Epoch 45/50\n",
      "328/328 [==============================] - 1s 2ms/step - loss: 0.1527\n",
      "Epoch 46/50\n",
      "328/328 [==============================] - 0s 1ms/step - loss: 0.1507\n",
      "Epoch 47/50\n",
      "328/328 [==============================] - 0s 1ms/step - loss: 0.1485\n",
      "Epoch 48/50\n",
      "328/328 [==============================] - 0s 1ms/step - loss: 0.1475\n",
      "Epoch 49/50\n",
      "328/328 [==============================] - 0s 1ms/step - loss: 0.1473\n",
      "Epoch 50/50\n",
      "328/328 [==============================] - 0s 1ms/step - loss: 0.1467\n",
      "Model - CNN:\n",
      "Accuracy Score: 0.7665776591010236\n"
     ]
    }
   ],
   "source": [
    "# build CNN model\n",
    "cnn_model=cnn(X_train,y_train)\n",
    "cnn_predictions = get_result(cnn_model, X_test, y_test, \"CNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " time_distributed (TimeDistr  (None, None, 13, 64)     192       \n",
      " ibuted)                                                         \n",
      "                                                                 \n",
      " time_distributed_1 (TimeDis  (None, None, 6, 64)      0         \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " time_distributed_2 (TimeDis  (None, None, 384)        0         \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 15)                24000     \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 1)                 16        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24,208\n",
      "Trainable params: 24,208\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "328/328 [==============================] - 2s 2ms/step - loss: 0.2528\n",
      "Epoch 2/50\n",
      "328/328 [==============================] - 1s 2ms/step - loss: 0.2936\n",
      "Epoch 3/50\n",
      "328/328 [==============================] - 1s 2ms/step - loss: 0.4256\n",
      "Epoch 4/50\n",
      "328/328 [==============================] - 1s 2ms/step - loss: 0.2284\n",
      "Epoch 5/50\n",
      "328/328 [==============================] - 1s 2ms/step - loss: 0.2270\n",
      "Epoch 6/50\n",
      "328/328 [==============================] - 1s 2ms/step - loss: 0.2251A: 0s - loss\n",
      "Epoch 7/50\n",
      "328/328 [==============================] - 1s 2ms/step - loss: 0.2239\n",
      "Epoch 8/50\n",
      "328/328 [==============================] - 1s 2ms/step - loss: 0.2230\n",
      "Epoch 9/50\n",
      "328/328 [==============================] - 1s 2ms/step - loss: 0.2219\n",
      "Epoch 10/50\n",
      "328/328 [==============================] - 1s 2ms/step - loss: 0.2210\n",
      "Epoch 11/50\n",
      "328/328 [==============================] - 1s 2ms/step - loss: 0.2439\n",
      "Epoch 12/50\n",
      "328/328 [==============================] - 1s 2ms/step - loss: 0.2191\n",
      "Epoch 13/50\n",
      "328/328 [==============================] - 1s 2ms/step - loss: 0.2178\n",
      "Epoch 14/50\n",
      "328/328 [==============================] - 1s 2ms/step - loss: 0.2165\n",
      "Epoch 15/50\n",
      "328/328 [==============================] - 1s 2ms/step - loss: 0.2152\n",
      "Epoch 16/50\n",
      "328/328 [==============================] - 1s 2ms/step - loss: 0.2145\n",
      "Epoch 17/50\n",
      "328/328 [==============================] - 1s 2ms/step - loss: 0.2129\n",
      "Epoch 18/50\n",
      "328/328 [==============================] - 1s 2ms/step - loss: 0.2115\n",
      "Epoch 19/50\n",
      "328/328 [==============================] - 1s 2ms/step - loss: 0.2106\n",
      "Epoch 20/50\n",
      "328/328 [==============================] - 1s 2ms/step - loss: 0.2091\n",
      "Epoch 21/50\n",
      "328/328 [==============================] - 1s 2ms/step - loss: 0.2074\n",
      "Epoch 22/50\n",
      "328/328 [==============================] - 1s 2ms/step - loss: 0.2055\n",
      "Epoch 23/50\n",
      "328/328 [==============================] - 1s 2ms/step - loss: 0.2042\n",
      "Epoch 24/50\n",
      "328/328 [==============================] - 1s 2ms/step - loss: 0.2023\n",
      "Epoch 25/50\n",
      "328/328 [==============================] - 1s 2ms/step - loss: 0.2012\n",
      "Epoch 26/50\n",
      "328/328 [==============================] - 1s 2ms/step - loss: 0.1992\n",
      "Epoch 27/50\n",
      "328/328 [==============================] - 1s 2ms/step - loss: 0.1975\n",
      "Epoch 28/50\n",
      "328/328 [==============================] - 1s 2ms/step - loss: 0.1953\n",
      "Epoch 29/50\n",
      "328/328 [==============================] - 1s 2ms/step - loss: 0.1932\n",
      "Epoch 30/50\n",
      "328/328 [==============================] - 1s 2ms/step - loss: 0.1908\n",
      "Epoch 31/50\n",
      "328/328 [==============================] - 1s 2ms/step - loss: 0.1898\n",
      "Epoch 32/50\n",
      "328/328 [==============================] - 1s 2ms/step - loss: 0.1874\n",
      "Epoch 33/50\n",
      "328/328 [==============================] - 1s 2ms/step - loss: 0.1869\n",
      "Epoch 34/50\n",
      "328/328 [==============================] - 1s 2ms/step - loss: 0.1841\n",
      "Epoch 35/50\n",
      "328/328 [==============================] - 1s 2ms/step - loss: 0.1823\n",
      "Epoch 36/50\n",
      "328/328 [==============================] - 1s 2ms/step - loss: 0.1820\n",
      "Epoch 37/50\n",
      "328/328 [==============================] - 1s 2ms/step - loss: 0.1794\n",
      "Epoch 38/50\n",
      "328/328 [==============================] - 1s 2ms/step - loss: 0.1783\n",
      "Epoch 39/50\n",
      "328/328 [==============================] - 1s 2ms/step - loss: 0.1762\n",
      "Epoch 40/50\n",
      "328/328 [==============================] - 1s 2ms/step - loss: 0.1748\n",
      "Epoch 41/50\n",
      "328/328 [==============================] - 1s 2ms/step - loss: 0.1735\n",
      "Epoch 42/50\n",
      "328/328 [==============================] - 1s 2ms/step - loss: 0.1725\n",
      "Epoch 43/50\n",
      "328/328 [==============================] - 1s 2ms/step - loss: 0.1708\n",
      "Epoch 44/50\n",
      "328/328 [==============================] - 1s 2ms/step - loss: 0.1703\n",
      "Epoch 45/50\n",
      "328/328 [==============================] - 1s 2ms/step - loss: 0.1689\n",
      "Epoch 46/50\n",
      "328/328 [==============================] - 1s 2ms/step - loss: 0.1680\n",
      "Epoch 47/50\n",
      "328/328 [==============================] - 1s 2ms/step - loss: 0.1669\n",
      "Epoch 48/50\n",
      "328/328 [==============================] - 1s 2ms/step - loss: 0.1653\n",
      "Epoch 49/50\n",
      "328/328 [==============================] - 1s 2ms/step - loss: 0.1655\n",
      "Epoch 50/50\n",
      "328/328 [==============================] - 1s 2ms/step - loss: 0.1634\n",
      "Model - CNN-LSTM:\n",
      "Accuracy Score: 0.7578994214508233\n"
     ]
    }
   ],
   "source": [
    "# build CNN-LSTM model\n",
    "n_seq=1\n",
    "cnn_lstm_model=cnn_lstm(X_train,y_train)\n",
    "cnn_lstm_predictions = get_result(cnn_lstm_model, X_test.reshape((X_test.shape[0], n_seq, X_test.shape[1], 1)), y_test, \"CNN-LSTM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv_lstm2d (ConvLSTM2D)    (None, 1, 13, 64)         33536     \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 832)               0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 20)                16660     \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 10)                210       \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50,417\n",
      "Trainable params: 50,417\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "328/328 [==============================] - 3s 4ms/step - loss: 0.2784\n",
      "Epoch 2/50\n",
      "328/328 [==============================] - 2s 5ms/step - loss: 0.2385\n",
      "Epoch 3/50\n",
      "328/328 [==============================] - 2s 5ms/step - loss: 0.2278\n",
      "Epoch 4/50\n",
      "328/328 [==============================] - 2s 5ms/step - loss: 0.2219\n",
      "Epoch 5/50\n",
      "328/328 [==============================] - 2s 5ms/step - loss: 0.2167\n",
      "Epoch 6/50\n",
      "328/328 [==============================] - 1s 5ms/step - loss: 0.2135\n",
      "Epoch 7/50\n",
      "328/328 [==============================] - 1s 4ms/step - loss: 0.2174\n",
      "Epoch 8/50\n",
      "328/328 [==============================] - 1s 4ms/step - loss: 0.2061\n",
      "Epoch 9/50\n",
      "328/328 [==============================] - 1s 4ms/step - loss: 0.2000\n",
      "Epoch 10/50\n",
      "328/328 [==============================] - 1s 4ms/step - loss: 0.1959\n",
      "Epoch 11/50\n",
      "328/328 [==============================] - 1s 4ms/step - loss: 0.1944\n",
      "Epoch 12/50\n",
      "328/328 [==============================] - 2s 5ms/step - loss: 0.1867\n",
      "Epoch 13/50\n",
      "328/328 [==============================] - 1s 5ms/step - loss: 0.1829\n",
      "Epoch 14/50\n",
      "328/328 [==============================] - 2s 5ms/step - loss: 0.1785\n",
      "Epoch 15/50\n",
      "328/328 [==============================] - 2s 5ms/step - loss: 0.1758\n",
      "Epoch 16/50\n",
      "328/328 [==============================] - 2s 5ms/step - loss: 0.1725\n",
      "Epoch 17/50\n",
      "328/328 [==============================] - 1s 4ms/step - loss: 0.1700\n",
      "Epoch 18/50\n",
      "328/328 [==============================] - 2s 5ms/step - loss: 0.1670\n",
      "Epoch 19/50\n",
      "328/328 [==============================] - 2s 5ms/step - loss: 0.1645\n",
      "Epoch 20/50\n",
      "328/328 [==============================] - 2s 5ms/step - loss: 0.1651\n",
      "Epoch 21/50\n",
      "328/328 [==============================] - 1s 4ms/step - loss: 0.1606\n",
      "Epoch 22/50\n",
      "328/328 [==============================] - 1s 4ms/step - loss: 0.1587\n",
      "Epoch 23/50\n",
      "328/328 [==============================] - 1s 4ms/step - loss: 0.1590\n",
      "Epoch 24/50\n",
      "328/328 [==============================] - 1s 5ms/step - loss: 0.2768\n",
      "Epoch 25/50\n",
      "328/328 [==============================] - 1s 4ms/step - loss: 0.1552\n",
      "Epoch 26/50\n",
      "328/328 [==============================] - 1s 4ms/step - loss: 0.1540\n",
      "Epoch 27/50\n",
      "328/328 [==============================] - 1s 5ms/step - loss: 0.1533\n",
      "Epoch 28/50\n",
      "328/328 [==============================] - 1s 4ms/step - loss: 0.1517\n",
      "Epoch 29/50\n",
      "328/328 [==============================] - 2s 5ms/step - loss: 0.1504\n",
      "Epoch 30/50\n",
      "328/328 [==============================] - 2s 5ms/step - loss: 0.1495\n",
      "Epoch 31/50\n",
      "328/328 [==============================] - 1s 4ms/step - loss: 0.1498\n",
      "Epoch 32/50\n",
      "328/328 [==============================] - 2s 5ms/step - loss: 0.1474\n",
      "Epoch 33/50\n",
      "328/328 [==============================] - 2s 5ms/step - loss: 0.1469\n",
      "Epoch 34/50\n",
      "328/328 [==============================] - 2s 5ms/step - loss: 0.1463\n",
      "Epoch 35/50\n",
      "328/328 [==============================] - 1s 4ms/step - loss: 0.1455\n",
      "Epoch 36/50\n",
      "328/328 [==============================] - 2s 5ms/step - loss: 0.1443\n",
      "Epoch 37/50\n",
      "328/328 [==============================] - 2s 5ms/step - loss: 0.1436\n",
      "Epoch 38/50\n",
      "328/328 [==============================] - 2s 6ms/step - loss: 0.1429\n",
      "Epoch 39/50\n",
      "328/328 [==============================] - 2s 5ms/step - loss: 0.1411\n",
      "Epoch 40/50\n",
      "328/328 [==============================] - 2s 6ms/step - loss: 0.1417\n",
      "Epoch 41/50\n",
      "328/328 [==============================] - 2s 6ms/step - loss: 0.1397\n",
      "Epoch 42/50\n",
      "328/328 [==============================] - 3s 8ms/step - loss: 0.1393\n",
      "Epoch 43/50\n",
      "328/328 [==============================] - 2s 5ms/step - loss: 0.1389\n",
      "Epoch 44/50\n",
      "328/328 [==============================] - 1s 4ms/step - loss: 0.1376\n",
      "Epoch 45/50\n",
      "328/328 [==============================] - 1s 4ms/step - loss: 0.1372\n",
      "Epoch 46/50\n",
      "328/328 [==============================] - 2s 5ms/step - loss: 0.1350\n",
      "Epoch 47/50\n",
      "328/328 [==============================] - 1s 4ms/step - loss: 0.1346\n",
      "Epoch 48/50\n",
      "328/328 [==============================] - 1s 4ms/step - loss: 0.1353\n",
      "Epoch 49/50\n",
      "328/328 [==============================] - 2s 5ms/step - loss: 0.1338\n",
      "Epoch 50/50\n",
      "328/328 [==============================] - 1s 4ms/step - loss: 0.1355\n",
      "Model - ConvLSTM:\n",
      "Accuracy Score: 0.7906097018246551\n"
     ]
    }
   ],
   "source": [
    "# build ConvLSTM model\n",
    "n_seq=1\n",
    "n_features = 1\n",
    "conv_lstm_model=convlstm(X_train,y_train)\n",
    "conv_lstm_predictions = get_result(conv_lstm_model, X_test.reshape((X_test.shape[0], n_seq, 1, X_test.shape[1], n_features)), y_test, \"ConvLSTM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial Attacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attack Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def signed_gradient(X_test, y): \n",
    "    y =  y[:,0].astype(dtype=np.float32)\n",
    "    X_tf = tf.convert_to_tensor(X_test, dtype=tf.float32)\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(X_tf)\n",
    "        lossFunction = mean_squared_error(X_tf, y.reshape(-1))\n",
    "    gradientFunction = tape.gradient(lossFunction, X_tf)\n",
    "    signed_grad = tf.sign(gradientFunction)\n",
    "    return signed_grad.numpy()\n",
    "\n",
    "def fgsm(X_test, y, epsilon=0.1):\n",
    "    signed_grad = signed_gradient(X_test, y)\n",
    "    X_perturbed = X_test + epsilon * signed_grad\n",
    "    return X_perturbed\n",
    "\n",
    "def bim(iterations, epsilon, alpha, X_test, y, final_X_only = True):\n",
    "    X_perturbed = X_test.copy()\n",
    "    for i in range(iterations):\n",
    "        n = alpha * signed_gradient(X_perturbed, y)\n",
    "        X_perturbed += n\n",
    "        maxValues = np.maximum((X_test-epsilon), np.array(X_perturbed)) \n",
    "        X_perturbed = np.minimum((X_test+epsilon), maxValues)\n",
    "       \n",
    "        return X_perturbed\n",
    "def pgd(iterations, epsilon, alpha, X_test, y, final_X_only = True):\n",
    "    X_perturbed = X_test + np.random.uniform(-epsilon,epsilon,X_test.shape)\n",
    "    for i in range(iterations):\n",
    "        n = alpha * signed_gradient(X_perturbed, y)\n",
    "        X_perturbed += n\n",
    "        maxValues = np.maximum((X_test-epsilon), np.array(X_perturbed)) \n",
    "        X_perturbed = np.minimum((X_test+epsilon), maxValues)\n",
    "        \n",
    "        \n",
    "        return X_perturbed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attacks on Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 0.3\n",
    "alpha = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attacks on LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model - FGSM perturbed LSTM:\n",
      "Accuracy Score: 0.5854472630173565\n"
     ]
    }
   ],
   "source": [
    "X_fgsm_perturbed_lstm = fgsm(X_test, y_test, epsilon) \n",
    "fgsm_predictions_lstm = get_result(lstm_model, X_fgsm_perturbed_lstm, y_test, \"FGSM perturbed LSTM\")\n",
    "#plot_predictions(y_test, fgsm_predictions_lstm, \"FGSM perturbed LSTM\", xLabel=\"Time\", yLabel=\"Power Consumption\", realLabel=\"Actual power consumption\", predictedLabel=\"Predicted power consumption\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this to show intermediate results\n",
    "# bim(lstm_model, 5, 0.1, 0.05, X_test, y_test, final_X_only = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model - BIM perturbed LSTM:\n",
      "Accuracy Score: 0.7283044058744993\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_bim_perturbed_lstm = bim(5, epsilon, alpha, X_test, y_test)\n",
    "bim_predictions_lstm = get_result(lstm_model, X_bim_perturbed_lstm, y_test, \"BIM perturbed LSTM\")\n",
    "#plot_predictions(y_test, bim_predictions_lstm, \"BIM perturbed LSTM\", xLabel=\"Time\", yLabel=\"Power Consumption\", realLabel=\"Actual power consumption\", predictedLabel=\"Predicted power consumption\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this to show intermediate results\n",
    "# pgd(lstm_model, 5, 0.1, 0.05, X_test, y_test, final_X_only =False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model - PGD perturbed LSTM:\n",
      "Accuracy Score: 0.6243880729862038\n"
     ]
    }
   ],
   "source": [
    "X_pgd_perturbed_lstm = pgd(5, epsilon, alpha, X_test, y_test)\n",
    "pgd_predictions_lstm = get_result(lstm_model, X_pgd_perturbed_lstm, y_test, \"PGD perturbed LSTM\")\n",
    "#plot_predictions(y_test, pgd_predictions_lstm, \"PGD perturbed LSTM\", xLabel=\"Time\", yLabel=\"Power Consumption\", realLabel=\"Actual power consumption\", predictedLabel=\"Predicted power consumption\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attacks on Stacked LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# need to copy the same things above\n",
    "# replace the variable names carefully\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model - FGSM perturbed Stacked LSTM:\n",
      "Accuracy Score: 0.6259457053849578\n"
     ]
    }
   ],
   "source": [
    "X_fgsm_perturbed_stlstm = fgsm(X_test, y_test, epsilon) \n",
    "fgsm_predictions_stlstm = get_result(s_lstm_model, X_fgsm_perturbed_stlstm, y_test, \"FGSM perturbed Stacked LSTM\")\n",
    "#plot_predictions(y_test, fgsm_predictions_stlstm, \"FGSM perturbed Stacked LSTM\", xLabel=\"Time\", yLabel=\"Power Consumption\", realLabel=\"Actual power consumption\", predictedLabel=\"Predicted power consumption\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model - BIM perturbed Stacked LSTM:\n",
      "Accuracy Score: 0.7485536270583\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_bim_perturbed_stlstm = bim(5, epsilon, alpha, X_test, y_test)\n",
    "bim_predictions_stlstm = get_result(s_lstm_model, X_bim_perturbed_stlstm, y_test, \"BIM perturbed Stacked LSTM\")\n",
    "#plot_predictions(y_test, bim_predictions_stlstm, \"BIM perturbed Stacked LSTM\", xLabel=\"Time\", yLabel=\"Power Consumption\", realLabel=\"Actual power consumption\", predictedLabel=\"Predicted power consumption\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model - PGD perturbed Stacked LSTM:\n",
      "Accuracy Score: 0.678237650200267\n"
     ]
    }
   ],
   "source": [
    "X_pgd_perturbed_stlstm = pgd(5, 0.2, 0.05, X_test, y_test)\n",
    "pgd_predictions_stlstm = get_result(s_lstm_model, X_pgd_perturbed_stlstm, y_test, \"PGD perturbed Stacked LSTM\")\n",
    "#plot_predictions(y_test, pgd_predictions_stlstm, \"PGD perturbed Stacked LSTM\", xLabel=\"Time\", yLabel=\"Power Consumption\", realLabel=\"Actual power consumption\", predictedLabel=\"Predicted power consumption\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attacks on GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model - FGSM perturbed GRU:\n",
      "Accuracy Score: 0.5974632843791722\n"
     ]
    }
   ],
   "source": [
    "# need to copy the same things above\n",
    "# replace the variable names carefully\n",
    "X_fgsm_perturbed_gru = fgsm(X_test, y_test, epsilon) \n",
    "fgsm_predictions_gru = get_result(gru_model, X_fgsm_perturbed_gru, y_test, \"FGSM perturbed GRU\")\n",
    "#plot_predictions(y_test, fgsm_predictions_gru, \"FGSM perturbed GRU\", xLabel=\"Time\", yLabel=\"Power Consumption\", realLabel=\"Actual power consumption\", predictedLabel=\"Predicted power consumption\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model - BIM perturbed GRU:\n",
      "Accuracy Score: 0.7474410324877615\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_bim_perturbed_gru = bim(5, epsilon, alpha, X_test, y_test)\n",
    "bim_predictions_gru = get_result(gru_model, X_bim_perturbed_gru, y_test, \"BIM perturbed GRU\")\n",
    "#plot_predictions(y_test, bim_predictions_gru, \"BIM perturbed GRU\", xLabel=\"Time\", yLabel=\"Power Consumption\", realLabel=\"Actual power consumption\", predictedLabel=\"Predicted power consumption\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model - PGD perturbed GRU:\n",
      "Accuracy Score: 0.6199376947040498\n"
     ]
    }
   ],
   "source": [
    "X_pgd_perturbed_gru = pgd(5, epsilon, alpha, X_test, y_test)\n",
    "pgd_predictions_gru = get_result(gru_model, X_pgd_perturbed_gru, y_test, \"PGD perturbed GRU\")\n",
    "#plot_predictions(y_test, pgd_predictions_gru, \"PGD perturbed GRU\", xLabel=\"Time\", yLabel=\"Power Consumption\", realLabel=\"Actual power consumption\", predictedLabel=\"Predicted power consumption\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attacks on RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model - FGSM perturbed RNN:\n",
      "Accuracy Score: 0.6591010235870048\n"
     ]
    }
   ],
   "source": [
    "X_fgsm_perturbed_rnn = fgsm(X_test, y_test, epsilon) \n",
    "fgsm_predictions_rnn = get_result(rnn_model, X_fgsm_perturbed_rnn, y_test, \"FGSM perturbed RNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model - BIM perturbed RNN:\n",
      "Accuracy Score: 0.7222963951935915\n"
     ]
    }
   ],
   "source": [
    "X_bim_perturbed_rnn = bim(5, epsilon, alpha, X_test, y_test)\n",
    "bim_predictions_rnn = get_result(rnn_model, X_bim_perturbed_rnn, y_test, \"BIM perturbed RNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model - PGD perturbed RNN:\n",
      "Accuracy Score: 0.6388518024032043\n"
     ]
    }
   ],
   "source": [
    "X_pgd_perturbed_rnn = pgd(5, epsilon, alpha, X_test, y_test)\n",
    "pgd_predictions_rnn = get_result(rnn_model, X_pgd_perturbed_rnn, y_test, \"PGD perturbed RNN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Attacks on CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model - FGSM perturbed CNN:\n",
      "Accuracy Score: 0.6673342234089897\n"
     ]
    }
   ],
   "source": [
    "X_fgsm_perturbed_cnn = fgsm(X_test, y_test, epsilon) \n",
    "fgsm_predictions_cnn = get_result(cnn_model, X_fgsm_perturbed_cnn, y_test, \"FGSM perturbed CNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model - BIM perturbed CNN:\n",
      "Accuracy Score: 0.7427681352914998\n"
     ]
    }
   ],
   "source": [
    "X_bim_perturbed_cnn = bim(5, epsilon, alpha, X_test, y_test)\n",
    "bim_predictions_cnn = get_result(cnn_model, X_bim_perturbed_cnn, y_test, \"BIM perturbed CNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model - PGD perturbed CNN:\n",
      "Accuracy Score: 0.6582109479305741\n"
     ]
    }
   ],
   "source": [
    "X_pgd_perturbed_cnn = pgd(5, epsilon, alpha, X_test, y_test)\n",
    "pgd_predictions_cnn = get_result(cnn_model, X_pgd_perturbed_cnn, y_test, \"PGD perturbed CNN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Attacks on CNN-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model - CNN-LSTM:\n",
      "Accuracy Score: 0.5400534045393859\n"
     ]
    }
   ],
   "source": [
    "X_fgsm_perturbed_cnnlstm = fgsm(X_test, y_test, epsilon) \n",
    "fgsm_predictions_cnnlstm = get_result(cnn_lstm_model, X_fgsm_perturbed_cnnlstm.reshape((X_fgsm_perturbed_cnnlstm.shape[0], n_seq, X_fgsm_perturbed_cnnlstm.shape[1], 1)), y_test, \"CNN-LSTM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model - BIM CNN-LSTM:\n",
      "Accuracy Score: 0.6975967957276369\n"
     ]
    }
   ],
   "source": [
    "X_bim_perturbed_cnnlstm = bim(5, epsilon, alpha, X_test, y_test) \n",
    "bim_predictions_cnnlstm = get_result(cnn_lstm_model, X_bim_perturbed_cnnlstm.reshape((X_bim_perturbed_cnnlstm.shape[0], n_seq, X_bim_perturbed_cnnlstm.shape[1], 1)), y_test, \"BIM CNN-LSTM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model - PGD CNN-LSTM:\n",
      "Accuracy Score: 0.5976858032932799\n"
     ]
    }
   ],
   "source": [
    "X_pgd_perturbed_cnnlstm = pgd(5, epsilon, alpha, X_test, y_test) \n",
    "pgd_predictions_cnnlstm = get_result(cnn_lstm_model, X_pgd_perturbed_cnnlstm.reshape((X_pgd_perturbed_cnnlstm.shape[0], n_seq, X_pgd_perturbed_cnnlstm.shape[1], 1)), y_test, \"PGD CNN-LSTM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attacks on ConvLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model - Conv-LSTM:\n",
      "Accuracy Score: 0.6165999109924344\n"
     ]
    }
   ],
   "source": [
    "X_fgsm_perturbed_convlstm = fgsm(X_test, y_test, epsilon) \n",
    "fgsm_predictions_convlstm = get_result(conv_lstm_model, X_fgsm_perturbed_convlstm.reshape((X_fgsm_perturbed_convlstm.shape[0], n_seq,1, X_fgsm_perturbed_convlstm.shape[1], 1)), y_test, \"Conv-LSTM\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model - BIM ConvLSTM:\n",
      "Accuracy Score: 0.7590120160213618\n"
     ]
    }
   ],
   "source": [
    "X_bim_perturbed_convlstm = bim(5, epsilon, alpha, X_test, y_test) \n",
    "bim_predictions_convlstm = get_result(conv_lstm_model, X_bim_perturbed_convlstm.reshape((X_bim_perturbed_convlstm.shape[0], n_seq,1, X_bim_perturbed_convlstm.shape[1], 1)), y_test, \"BIM ConvLSTM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model - PGD ConvLSTM:\n",
      "Accuracy Score: 0.566533155318202\n"
     ]
    }
   ],
   "source": [
    "X_pgd_perturbed_convlstm = pgd(5, epsilon, alpha, X_test, y_test) \n",
    "pgd_predictions_convlstm = get_result(conv_lstm_model, X_pgd_perturbed_convlstm.reshape((X_pgd_perturbed_convlstm.shape[0], n_seq,1, X_pgd_perturbed_convlstm.shape[1], 1)), y_test, \"PGD ConvLSTM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adversarial Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_Y=np.concatenate((y_train,y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_8 (LSTM)               (None, 128)               66560     \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,689\n",
      "Trainable params: 66,689\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "656/656 [==============================] - 8s 8ms/step - loss: 0.6720 - accuracy: 0.5765\n",
      "Epoch 2/40\n",
      "656/656 [==============================] - 5s 7ms/step - loss: 0.6313 - accuracy: 0.6277\n",
      "Epoch 3/40\n",
      "656/656 [==============================] - 5s 7ms/step - loss: 0.5935 - accuracy: 0.6685\n",
      "Epoch 4/40\n",
      "656/656 [==============================] - 5s 7ms/step - loss: 0.5497 - accuracy: 0.7069\n",
      "Epoch 5/40\n",
      "656/656 [==============================] - 5s 7ms/step - loss: 0.5115 - accuracy: 0.7372\n",
      "Epoch 6/40\n",
      "656/656 [==============================] - 5s 7ms/step - loss: 0.4787 - accuracy: 0.7625\n",
      "Epoch 7/40\n",
      "656/656 [==============================] - 5s 7ms/step - loss: 0.4511 - accuracy: 0.7783\n",
      "Epoch 8/40\n",
      "656/656 [==============================] - 5s 7ms/step - loss: 0.4276 - accuracy: 0.7931\n",
      "Epoch 9/40\n",
      "656/656 [==============================] - 5s 7ms/step - loss: 0.4091 - accuracy: 0.8039\n",
      "Epoch 10/40\n",
      "656/656 [==============================] - 5s 7ms/step - loss: 0.3918 - accuracy: 0.8120\n",
      "Epoch 11/40\n",
      "656/656 [==============================] - 5s 8ms/step - loss: 0.3709 - accuracy: 0.8258\n",
      "Epoch 12/40\n",
      "656/656 [==============================] - 5s 7ms/step - loss: 0.3587 - accuracy: 0.8323\n",
      "Epoch 13/40\n",
      "656/656 [==============================] - 5s 7ms/step - loss: 0.3434 - accuracy: 0.8377\n",
      "Epoch 14/40\n",
      "656/656 [==============================] - 5s 7ms/step - loss: 0.3334 - accuracy: 0.8472\n",
      "Epoch 15/40\n",
      "656/656 [==============================] - 5s 7ms/step - loss: 0.3164 - accuracy: 0.8561\n",
      "Epoch 16/40\n",
      "656/656 [==============================] - 5s 8ms/step - loss: 0.3064 - accuracy: 0.8612\n",
      "Epoch 17/40\n",
      "656/656 [==============================] - 5s 7ms/step - loss: 0.2947 - accuracy: 0.8672\n",
      "Epoch 18/40\n",
      "656/656 [==============================] - 5s 7ms/step - loss: 0.2851 - accuracy: 0.8699\n",
      "Epoch 19/40\n",
      "656/656 [==============================] - 5s 7ms/step - loss: 0.2735 - accuracy: 0.8762\n",
      "Epoch 20/40\n",
      "656/656 [==============================] - 5s 7ms/step - loss: 0.2623 - accuracy: 0.8849\n",
      "Epoch 21/40\n",
      "656/656 [==============================] - 5s 7ms/step - loss: 0.2519 - accuracy: 0.8885\n",
      "Epoch 22/40\n",
      "656/656 [==============================] - 5s 7ms/step - loss: 0.2414 - accuracy: 0.8940\n",
      "Epoch 23/40\n",
      "656/656 [==============================] - 5s 7ms/step - loss: 0.2338 - accuracy: 0.8974\n",
      "Epoch 24/40\n",
      "656/656 [==============================] - 5s 7ms/step - loss: 0.2238 - accuracy: 0.9068\n",
      "Epoch 25/40\n",
      "656/656 [==============================] - 5s 7ms/step - loss: 0.2139 - accuracy: 0.9083\n",
      "Epoch 26/40\n",
      "656/656 [==============================] - 5s 7ms/step - loss: 0.2077 - accuracy: 0.9125\n",
      "Epoch 27/40\n",
      "656/656 [==============================] - 5s 7ms/step - loss: 0.1976 - accuracy: 0.9167\n",
      "Epoch 28/40\n",
      "656/656 [==============================] - 5s 7ms/step - loss: 0.1919 - accuracy: 0.9187\n",
      "Epoch 29/40\n",
      "656/656 [==============================] - 5s 7ms/step - loss: 0.1830 - accuracy: 0.9234\n",
      "Epoch 30/40\n",
      "656/656 [==============================] - 5s 7ms/step - loss: 0.1813 - accuracy: 0.9252\n",
      "Epoch 31/40\n",
      "656/656 [==============================] - 5s 7ms/step - loss: 0.1685 - accuracy: 0.9307\n",
      "Epoch 32/40\n",
      "656/656 [==============================] - 5s 7ms/step - loss: 0.1628 - accuracy: 0.9351\n",
      "Epoch 33/40\n",
      "656/656 [==============================] - 5s 7ms/step - loss: 0.1589 - accuracy: 0.9359\n",
      "Epoch 34/40\n",
      "656/656 [==============================] - 5s 7ms/step - loss: 0.1552 - accuracy: 0.9374\n",
      "Epoch 35/40\n",
      "656/656 [==============================] - 5s 7ms/step - loss: 0.1459 - accuracy: 0.9401\n",
      "Epoch 36/40\n",
      "656/656 [==============================] - 5s 7ms/step - loss: 0.1394 - accuracy: 0.9453\n",
      "Epoch 37/40\n",
      "656/656 [==============================] - 5s 7ms/step - loss: 0.1349 - accuracy: 0.9456\n",
      "Epoch 38/40\n",
      "656/656 [==============================] - 5s 7ms/step - loss: 0.1360 - accuracy: 0.9478\n",
      "Epoch 39/40\n",
      "656/656 [==============================] - 5s 7ms/step - loss: 0.1276 - accuracy: 0.9491\n",
      "Epoch 40/40\n",
      "656/656 [==============================] - 5s 7ms/step - loss: 0.1199 - accuracy: 0.9524\n"
     ]
    }
   ],
   "source": [
    "# Create perturbed training set\n",
    "X_fgsm_perturbed_train = fgsm(X_train, y_train, epsilon)\n",
    "X_new_fgsm=np.concatenate((X_train,X_fgsm_perturbed_train))\n",
    "fgsm_lstm=lstm(X_new_fgsm,new_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model - FGSM-LSTM:\n",
      "Accuracy Score: 0.8277703604806409\n"
     ]
    }
   ],
   "source": [
    "lstm_fgsm_predictions=get_result(fgsm_lstm, X_test, y_test, \"FGSM-LSTM\")\n",
    "#plot_predictions(y_test, lstm_fgsm_predictions, \"FGSM-LSTM model (Clean)\", xLabel=\"Time\", yLabel=\"Power Consumption\", realLabel=\"Actual power consumption\", predictedLabel=\"Predicted power consumption\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model - FGSM-LSTM:\n",
      "Accuracy Score: 0.8128615932354251\n"
     ]
    }
   ],
   "source": [
    "lstm_fgsm_predictions=get_result(fgsm_lstm, X_fgsm_perturbed_lstm, y_test, \"FGSM-LSTM\")\n",
    "#plot_predictions(y_test, lstm_fgsm_predictions, \"FGSM-LSTM model(Perturbed)\", xLabel=\"Time\", yLabel=\"Power Consumption\", realLabel=\"Actual power consumption\", predictedLabel=\"Predicted power consumption\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_9 (LSTM)               (None, 128)               66560     \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,689\n",
      "Trainable params: 66,689\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "656/656 [==============================] - 7s 7ms/step - loss: 0.6703 - accuracy: 0.5789\n",
      "Epoch 2/40\n",
      "656/656 [==============================] - 5s 7ms/step - loss: 0.6189 - accuracy: 0.6425\n",
      "Epoch 3/40\n",
      "656/656 [==============================] - 5s 7ms/step - loss: 0.5647 - accuracy: 0.7010\n",
      "Epoch 4/40\n",
      "656/656 [==============================] - 5s 7ms/step - loss: 0.5144 - accuracy: 0.7371\n",
      "Epoch 5/40\n",
      "656/656 [==============================] - 5s 7ms/step - loss: 0.4671 - accuracy: 0.7693\n",
      "Epoch 6/40\n",
      "656/656 [==============================] - 5s 7ms/step - loss: 0.4350 - accuracy: 0.7901\n",
      "Epoch 7/40\n",
      "656/656 [==============================] - 5s 7ms/step - loss: 0.4114 - accuracy: 0.8044\n",
      "Epoch 8/40\n",
      "656/656 [==============================] - 5s 7ms/step - loss: 0.3892 - accuracy: 0.8149\n",
      "Epoch 9/40\n",
      "656/656 [==============================] - 5s 7ms/step - loss: 0.3718 - accuracy: 0.8281\n",
      "Epoch 10/40\n",
      "656/656 [==============================] - 5s 7ms/step - loss: 0.3556 - accuracy: 0.8334\n",
      "Epoch 11/40\n",
      "656/656 [==============================] - 5s 7ms/step - loss: 0.3351 - accuracy: 0.8455\n",
      "Epoch 12/40\n",
      "656/656 [==============================] - 5s 7ms/step - loss: 0.3231 - accuracy: 0.8533\n",
      "Epoch 13/40\n",
      "656/656 [==============================] - 5s 7ms/step - loss: 0.3077 - accuracy: 0.8582\n",
      "Epoch 14/40\n",
      "656/656 [==============================] - 5s 7ms/step - loss: 0.2899 - accuracy: 0.8729\n",
      "Epoch 15/40\n",
      "656/656 [==============================] - 5s 7ms/step - loss: 0.2761 - accuracy: 0.8768\n",
      "Epoch 16/40\n",
      "656/656 [==============================] - 5s 7ms/step - loss: 0.2674 - accuracy: 0.8819\n",
      "Epoch 17/40\n",
      "656/656 [==============================] - 5s 7ms/step - loss: 0.2565 - accuracy: 0.8861\n",
      "Epoch 18/40\n",
      "656/656 [==============================] - 5s 8ms/step - loss: 0.2381 - accuracy: 0.8956\n",
      "Epoch 19/40\n",
      "656/656 [==============================] - 6s 9ms/step - loss: 0.2304 - accuracy: 0.9000\n",
      "Epoch 20/40\n",
      "656/656 [==============================] - 6s 9ms/step - loss: 0.2167 - accuracy: 0.9055\n",
      "Epoch 21/40\n",
      "656/656 [==============================] - 6s 9ms/step - loss: 0.2080 - accuracy: 0.9112\n",
      "Epoch 22/40\n",
      "656/656 [==============================] - 6s 9ms/step - loss: 0.1912 - accuracy: 0.9192\n",
      "Epoch 23/40\n",
      "656/656 [==============================] - 6s 9ms/step - loss: 0.1846 - accuracy: 0.9219\n",
      "Epoch 24/40\n",
      "656/656 [==============================] - 6s 8ms/step - loss: 0.1790 - accuracy: 0.9257\n",
      "Epoch 25/40\n",
      "656/656 [==============================] - 6s 9ms/step - loss: 0.1684 - accuracy: 0.9307\n",
      "Epoch 26/40\n",
      "656/656 [==============================] - 6s 9ms/step - loss: 0.1600 - accuracy: 0.9344\n",
      "Epoch 27/40\n",
      "656/656 [==============================] - 5s 8ms/step - loss: 0.1475 - accuracy: 0.9405\n",
      "Epoch 28/40\n",
      "656/656 [==============================] - 5s 8ms/step - loss: 0.1481 - accuracy: 0.9397\n",
      "Epoch 29/40\n",
      "656/656 [==============================] - 6s 9ms/step - loss: 0.1363 - accuracy: 0.9451\n",
      "Epoch 30/40\n",
      "656/656 [==============================] - 5s 8ms/step - loss: 0.1307 - accuracy: 0.9478\n",
      "Epoch 31/40\n",
      "656/656 [==============================] - 5s 8ms/step - loss: 0.1211 - accuracy: 0.9529\n",
      "Epoch 32/40\n",
      "656/656 [==============================] - 5s 8ms/step - loss: 0.1210 - accuracy: 0.9528\n",
      "Epoch 33/40\n",
      "656/656 [==============================] - 5s 8ms/step - loss: 0.1200 - accuracy: 0.9535\n",
      "Epoch 34/40\n",
      "656/656 [==============================] - 5s 8ms/step - loss: 0.1111 - accuracy: 0.9562\n",
      "Epoch 35/40\n",
      "656/656 [==============================] - 5s 8ms/step - loss: 0.1069 - accuracy: 0.9605\n",
      "Epoch 36/40\n",
      "656/656 [==============================] - 5s 8ms/step - loss: 0.1007 - accuracy: 0.9617\n",
      "Epoch 37/40\n",
      "656/656 [==============================] - 5s 8ms/step - loss: 0.1009 - accuracy: 0.9645\n",
      "Epoch 38/40\n",
      "656/656 [==============================] - 5s 8ms/step - loss: 0.0941 - accuracy: 0.9654\n",
      "Epoch 39/40\n",
      "656/656 [==============================] - 5s 7ms/step - loss: 0.0931 - accuracy: 0.9649\n",
      "Epoch 40/40\n",
      "656/656 [==============================] - 5s 7ms/step - loss: 0.0957 - accuracy: 0.9646\n"
     ]
    }
   ],
   "source": [
    "# Create perturbed training set\n",
    "X_bim_perturbed_train = bim(5, epsilon, alpha, X_train, y_train)\n",
    "X_new_bim=np.concatenate((X_train,X_bim_perturbed_train))\n",
    "bim_lstm=lstm(X_new_bim,new_Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model - BIM-LSTM:\n",
      "Accuracy Score: 0.8297730307076101\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lstm_bim_predictions=get_result(bim_lstm, X_test, y_test, \"BIM-LSTM\")\n",
    "#plot_predictions(y_test, lstm_bim_predictions, \"BIM-LSTM model (Clean)\", xLabel=\"Time\", yLabel=\"Power Consumption\", realLabel=\"Actual power consumption\", predictedLabel=\"Predicted power consumption\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model - BIM-LSTM:\n",
      "Accuracy Score: 0.8246550956831331\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lstm_bim_predictions=get_result(bim_lstm, X_bim_perturbed_lstm, y_test, \"BIM-LSTM\")\n",
    "#plot_predictions(y_test, lstm_bim_predictions, \"BIM-LSTM model (Perturbed)\", xLabel=\"Time\", yLabel=\"Power Consumption\", realLabel=\"Actual power consumption\", predictedLabel=\"Predicted power consumption\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_10 (LSTM)              (None, 128)               66560     \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,689\n",
      "Trainable params: 66,689\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "656/656 [==============================] - 8s 9ms/step - loss: 0.6766 - accuracy: 0.5693\n",
      "Epoch 2/40\n",
      "656/656 [==============================] - 5s 8ms/step - loss: 0.6574 - accuracy: 0.5913\n",
      "Epoch 3/40\n",
      "656/656 [==============================] - 5s 7ms/step - loss: 0.6364 - accuracy: 0.6170\n",
      "Epoch 4/40\n",
      "656/656 [==============================] - 4s 7ms/step - loss: 0.6082 - accuracy: 0.6464\n",
      "Epoch 5/40\n",
      "656/656 [==============================] - 4s 7ms/step - loss: 0.5839 - accuracy: 0.6767\n",
      "Epoch 6/40\n",
      "656/656 [==============================] - 4s 7ms/step - loss: 0.5593 - accuracy: 0.6968\n",
      "Epoch 7/40\n",
      "656/656 [==============================] - 5s 7ms/step - loss: 0.5372 - accuracy: 0.7149\n",
      "Epoch 8/40\n",
      "656/656 [==============================] - 4s 7ms/step - loss: 0.5219 - accuracy: 0.7270\n",
      "Epoch 9/40\n",
      "656/656 [==============================] - 4s 7ms/step - loss: 0.5064 - accuracy: 0.7390\n",
      "Epoch 10/40\n",
      "656/656 [==============================] - 4s 7ms/step - loss: 0.4956 - accuracy: 0.7393\n",
      "Epoch 11/40\n",
      "656/656 [==============================] - 4s 7ms/step - loss: 0.4869 - accuracy: 0.7493\n",
      "Epoch 12/40\n",
      "656/656 [==============================] - 4s 7ms/step - loss: 0.4769 - accuracy: 0.7587\n",
      "Epoch 13/40\n",
      "656/656 [==============================] - 5s 7ms/step - loss: 0.4674 - accuracy: 0.7635\n",
      "Epoch 14/40\n",
      "656/656 [==============================] - 4s 7ms/step - loss: 0.4590 - accuracy: 0.7680\n",
      "Epoch 15/40\n",
      "656/656 [==============================] - 4s 7ms/step - loss: 0.4478 - accuracy: 0.7721\n",
      "Epoch 16/40\n",
      "656/656 [==============================] - 4s 7ms/step - loss: 0.4396 - accuracy: 0.7785\n",
      "Epoch 17/40\n",
      "656/656 [==============================] - 4s 7ms/step - loss: 0.4282 - accuracy: 0.7876\n",
      "Epoch 18/40\n",
      "656/656 [==============================] - 5s 7ms/step - loss: 0.4242 - accuracy: 0.7898\n",
      "Epoch 19/40\n",
      "656/656 [==============================] - 5s 7ms/step - loss: 0.4138 - accuracy: 0.7951\n",
      "Epoch 20/40\n",
      "656/656 [==============================] - 4s 7ms/step - loss: 0.4025 - accuracy: 0.8042\n",
      "Epoch 21/40\n",
      "656/656 [==============================] - 4s 7ms/step - loss: 0.3944 - accuracy: 0.8067\n",
      "Epoch 22/40\n",
      "656/656 [==============================] - 5s 7ms/step - loss: 0.3850 - accuracy: 0.8132\n",
      "Epoch 23/40\n",
      "656/656 [==============================] - 5s 7ms/step - loss: 0.3788 - accuracy: 0.8155\n",
      "Epoch 24/40\n",
      "656/656 [==============================] - 5s 7ms/step - loss: 0.3676 - accuracy: 0.8227\n",
      "Epoch 25/40\n",
      "656/656 [==============================] - 5s 7ms/step - loss: 0.3552 - accuracy: 0.8284\n",
      "Epoch 26/40\n",
      "656/656 [==============================] - 4s 7ms/step - loss: 0.3515 - accuracy: 0.8325\n",
      "Epoch 27/40\n",
      "656/656 [==============================] - 5s 7ms/step - loss: 0.3430 - accuracy: 0.8363\n",
      "Epoch 28/40\n",
      "656/656 [==============================] - 5s 7ms/step - loss: 0.3346 - accuracy: 0.8433\n",
      "Epoch 29/40\n",
      "656/656 [==============================] - 5s 7ms/step - loss: 0.3259 - accuracy: 0.8474\n",
      "Epoch 30/40\n",
      "656/656 [==============================] - 5s 7ms/step - loss: 0.3163 - accuracy: 0.8501\n",
      "Epoch 31/40\n",
      "656/656 [==============================] - 5s 7ms/step - loss: 0.3062 - accuracy: 0.8581\n",
      "Epoch 32/40\n",
      "656/656 [==============================] - 5s 7ms/step - loss: 0.3017 - accuracy: 0.8592\n",
      "Epoch 33/40\n",
      "656/656 [==============================] - 5s 7ms/step - loss: 0.2923 - accuracy: 0.8664\n",
      "Epoch 34/40\n",
      "656/656 [==============================] - 5s 7ms/step - loss: 0.2878 - accuracy: 0.8693\n",
      "Epoch 35/40\n",
      "656/656 [==============================] - 5s 7ms/step - loss: 0.2851 - accuracy: 0.8678\n",
      "Epoch 36/40\n",
      "656/656 [==============================] - 5s 7ms/step - loss: 0.2718 - accuracy: 0.8763\n",
      "Epoch 37/40\n",
      "656/656 [==============================] - 4s 7ms/step - loss: 0.2643 - accuracy: 0.8825\n",
      "Epoch 38/40\n",
      "656/656 [==============================] - 4s 7ms/step - loss: 0.2620 - accuracy: 0.8835\n",
      "Epoch 39/40\n",
      "656/656 [==============================] - 5s 7ms/step - loss: 0.2555 - accuracy: 0.8867\n",
      "Epoch 40/40\n",
      "656/656 [==============================] - 5s 7ms/step - loss: 0.2504 - accuracy: 0.8912\n"
     ]
    }
   ],
   "source": [
    "# Create perturbed training set\n",
    "X_pgd_perturbed_train = pgd(5, epsilon, alpha, X_train, y_train)\n",
    "X_new_pgd=np.concatenate((X_train,X_pgd_perturbed_train))\n",
    "pgd_lstm=lstm(X_new_pgd,new_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model - PGD-LSTM:\n",
      "Accuracy Score: 0.8188696039163329\n"
     ]
    }
   ],
   "source": [
    "lstm_pgd_predictions=get_result(pgd_lstm, X_test, y_test, \"PGD-LSTM\")\n",
    "#plot_predictions(y_test, lstm_pgd_predictions, \"PGD-LSTM model (Clean)\", xLabel=\"Time\", yLabel=\"Power Consumption\", realLabel=\"Actual power consumption\", predictedLabel=\"Predicted power consumption\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model - PGS-LSTM:\n",
      "Accuracy Score: 0.6513128615932354\n"
     ]
    }
   ],
   "source": [
    "lstm_pgd_predictions=get_result(pgd_lstm, X_pgd_perturbed_lstm, y_test, \"PGS-LSTM\")\n",
    "#plot_predictions(y_test, lstm_pgd_predictions, \"PGD-LSTM model (Perturbed)\", xLabel=\"Time\", yLabel=\"Power Consumption\", realLabel=\"Actual power consumption\", predictedLabel=\"Predicted power consumption\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stacked LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_11 (LSTM)              (None, 14, 50)            10400     \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 14, 50)            0         \n",
      "                                                                 \n",
      " lstm_12 (LSTM)              (None, 128)               91648     \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 102,177\n",
      "Trainable params: 102,177\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "656/656 [==============================] - 11s 11ms/step - loss: 0.6739 - accuracy: 0.5727\n",
      "Epoch 2/40\n",
      "656/656 [==============================] - 9s 13ms/step - loss: 0.6463 - accuracy: 0.6131\n",
      "Epoch 3/40\n",
      "656/656 [==============================] - 11s 16ms/step - loss: 0.6086 - accuracy: 0.6569\n",
      "Epoch 4/40\n",
      "656/656 [==============================] - 8s 13ms/step - loss: 0.5625 - accuracy: 0.6974\n",
      "Epoch 5/40\n",
      "656/656 [==============================] - 9s 13ms/step - loss: 0.5089 - accuracy: 0.7419\n",
      "Epoch 6/40\n",
      "656/656 [==============================] - 8s 12ms/step - loss: 0.4661 - accuracy: 0.7685\n",
      "Epoch 7/40\n",
      "656/656 [==============================] - 8s 12ms/step - loss: 0.4351 - accuracy: 0.7889\n",
      "Epoch 8/40\n",
      "656/656 [==============================] - 7s 11ms/step - loss: 0.4063 - accuracy: 0.8067\n",
      "Epoch 9/40\n",
      "656/656 [==============================] - 8s 12ms/step - loss: 0.3862 - accuracy: 0.8179\n",
      "Epoch 10/40\n",
      "656/656 [==============================] - 8s 12ms/step - loss: 0.3592 - accuracy: 0.8333\n",
      "Epoch 11/40\n",
      "656/656 [==============================] - 9s 14ms/step - loss: 0.3427 - accuracy: 0.8430 0s -\n",
      "Epoch 12/40\n",
      "656/656 [==============================] - 7s 11ms/step - loss: 0.3239 - accuracy: 0.8546\n",
      "Epoch 13/40\n",
      "656/656 [==============================] - 7s 11ms/step - loss: 0.3102 - accuracy: 0.8621\n",
      "Epoch 14/40\n",
      "656/656 [==============================] - 7s 11ms/step - loss: 0.2926 - accuracy: 0.8696\n",
      "Epoch 15/40\n",
      "656/656 [==============================] - 7s 11ms/step - loss: 0.2799 - accuracy: 0.8773\n",
      "Epoch 16/40\n",
      "656/656 [==============================] - 7s 11ms/step - loss: 0.2696 - accuracy: 0.8820\n",
      "Epoch 17/40\n",
      "656/656 [==============================] - 7s 11ms/step - loss: 0.2501 - accuracy: 0.8930\n",
      "Epoch 18/40\n",
      "656/656 [==============================] - 7s 11ms/step - loss: 0.2454 - accuracy: 0.8941\n",
      "Epoch 19/40\n",
      "656/656 [==============================] - 7s 11ms/step - loss: 0.2303 - accuracy: 0.9021\n",
      "Epoch 20/40\n",
      "656/656 [==============================] - 7s 11ms/step - loss: 0.2234 - accuracy: 0.9052\n",
      "Epoch 21/40\n",
      "656/656 [==============================] - 7s 11ms/step - loss: 0.2099 - accuracy: 0.9143\n",
      "Epoch 22/40\n",
      "656/656 [==============================] - 7s 11ms/step - loss: 0.2017 - accuracy: 0.9174\n",
      "Epoch 23/40\n",
      "656/656 [==============================] - 7s 11ms/step - loss: 0.1949 - accuracy: 0.9187\n",
      "Epoch 24/40\n",
      "656/656 [==============================] - 8s 12ms/step - loss: 0.1852 - accuracy: 0.9249\n",
      "Epoch 25/40\n",
      "656/656 [==============================] - 8s 12ms/step - loss: 0.1739 - accuracy: 0.9285\n",
      "Epoch 26/40\n",
      "656/656 [==============================] - 7s 11ms/step - loss: 0.1712 - accuracy: 0.9324\n",
      "Epoch 27/40\n",
      "656/656 [==============================] - 7s 11ms/step - loss: 0.1695 - accuracy: 0.9345\n",
      "Epoch 28/40\n",
      "656/656 [==============================] - 7s 11ms/step - loss: 0.1576 - accuracy: 0.9379\n",
      "Epoch 29/40\n",
      "656/656 [==============================] - 7s 11ms/step - loss: 0.1543 - accuracy: 0.9396\n",
      "Epoch 30/40\n",
      "656/656 [==============================] - 7s 11ms/step - loss: 0.1516 - accuracy: 0.9406\n",
      "Epoch 31/40\n",
      "656/656 [==============================] - 7s 11ms/step - loss: 0.1472 - accuracy: 0.9413\n",
      "Epoch 32/40\n",
      "656/656 [==============================] - 7s 11ms/step - loss: 0.1410 - accuracy: 0.9439\n",
      "Epoch 33/40\n",
      "656/656 [==============================] - 7s 11ms/step - loss: 0.1348 - accuracy: 0.9471\n",
      "Epoch 34/40\n",
      "656/656 [==============================] - 7s 11ms/step - loss: 0.1336 - accuracy: 0.9491\n",
      "Epoch 35/40\n",
      "656/656 [==============================] - 7s 11ms/step - loss: 0.1306 - accuracy: 0.9495\n",
      "Epoch 36/40\n",
      "656/656 [==============================] - 7s 11ms/step - loss: 0.1291 - accuracy: 0.9515\n",
      "Epoch 37/40\n",
      "656/656 [==============================] - 7s 11ms/step - loss: 0.1261 - accuracy: 0.9530\n",
      "Epoch 38/40\n",
      "656/656 [==============================] - 7s 11ms/step - loss: 0.1231 - accuracy: 0.9549\n",
      "Epoch 39/40\n",
      "656/656 [==============================] - 7s 11ms/step - loss: 0.1158 - accuracy: 0.9548\n",
      "Epoch 40/40\n",
      "656/656 [==============================] - 7s 11ms/step - loss: 0.1208 - accuracy: 0.9545\n"
     ]
    }
   ],
   "source": [
    "# Create perturbed training set\n",
    "X_fgsm_perturbed_train = fgsm(X_train, y_train, epsilon)\n",
    "X_new_fgsm=np.concatenate((X_train,X_fgsm_perturbed_train))\n",
    "fgsm_stlstm=stacked_lstm(X_new_fgsm,new_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model - FGSM-StackedLSTM:\n",
      "Accuracy Score: 0.8230974632843792\n"
     ]
    }
   ],
   "source": [
    "stlstm_fgsm_predictions=get_result(fgsm_stlstm, X_test, y_test, \"FGSM-StackedLSTM\")\n",
    "#plot_predictions(y_test, stlstm_fgsm_predictions, \"FGSM-LSTM model (Clean)\", xLabel=\"Time\", yLabel=\"Power Consumption\", realLabel=\"Actual power consumption\", predictedLabel=\"Predicted power consumption\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model - FGSM-StackedLSTM:\n",
      "Accuracy Score: 0.8182020471740098\n"
     ]
    }
   ],
   "source": [
    "stlstm_fgsm_predictions=get_result(fgsm_stlstm, X_fgsm_perturbed_stlstm, y_test, \"FGSM-StackedLSTM\")\n",
    "#plot_predictions(y_test, stlstm_fgsm_predictions, \"FGSM-LSTM model (Perturbed)\", xLabel=\"Time\", yLabel=\"Power Consumption\", realLabel=\"Actual power consumption\", predictedLabel=\"Predicted power consumption\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_13 (LSTM)              (None, 14, 50)            10400     \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 14, 50)            0         \n",
      "                                                                 \n",
      " lstm_14 (LSTM)              (None, 128)               91648     \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 102,177\n",
      "Trainable params: 102,177\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "656/656 [==============================] - 12s 12ms/step - loss: 0.6716 - accuracy: 0.5809\n",
      "Epoch 2/40\n",
      "656/656 [==============================] - 10s 16ms/step - loss: 0.6377 - accuracy: 0.6290\n",
      "Epoch 3/40\n",
      "656/656 [==============================] - 8s 12ms/step - loss: 0.5912 - accuracy: 0.6777\n",
      "Epoch 4/40\n",
      "656/656 [==============================] - 7s 10ms/step - loss: 0.5372 - accuracy: 0.7209\n",
      "Epoch 5/40\n",
      "656/656 [==============================] - 8s 12ms/step - loss: 0.4870 - accuracy: 0.7561\n",
      "Epoch 6/40\n",
      "656/656 [==============================] - 7s 11ms/step - loss: 0.4483 - accuracy: 0.7780\n",
      "Epoch 7/40\n",
      "656/656 [==============================] - 8s 11ms/step - loss: 0.4184 - accuracy: 0.7968\n",
      "Epoch 8/40\n",
      "656/656 [==============================] - 7s 11ms/step - loss: 0.3922 - accuracy: 0.8107\n",
      "Epoch 9/40\n",
      "656/656 [==============================] - 7s 11ms/step - loss: 0.3664 - accuracy: 0.8289\n",
      "Epoch 10/40\n",
      "656/656 [==============================] - 7s 10ms/step - loss: 0.3470 - accuracy: 0.8395\n",
      "Epoch 11/40\n",
      "656/656 [==============================] - 7s 11ms/step - loss: 0.3288 - accuracy: 0.8482\n",
      "Epoch 12/40\n",
      "656/656 [==============================] - 7s 11ms/step - loss: 0.3087 - accuracy: 0.8586\n",
      "Epoch 13/40\n",
      "656/656 [==============================] - 7s 11ms/step - loss: 0.2906 - accuracy: 0.8699\n",
      "Epoch 14/40\n",
      "656/656 [==============================] - 8s 11ms/step - loss: 0.2751 - accuracy: 0.8767\n",
      "Epoch 15/40\n",
      "656/656 [==============================] - 7s 10ms/step - loss: 0.2623 - accuracy: 0.8847\n",
      "Epoch 16/40\n",
      "656/656 [==============================] - 7s 10ms/step - loss: 0.2432 - accuracy: 0.8933\n",
      "Epoch 17/40\n",
      "656/656 [==============================] - 7s 10ms/step - loss: 0.2350 - accuracy: 0.8989\n",
      "Epoch 18/40\n",
      "656/656 [==============================] - 7s 11ms/step - loss: 0.2219 - accuracy: 0.9044\n",
      "Epoch 19/40\n",
      "656/656 [==============================] - 7s 11ms/step - loss: 0.2134 - accuracy: 0.9110\n",
      "Epoch 20/40\n",
      "656/656 [==============================] - 7s 11ms/step - loss: 0.1993 - accuracy: 0.9168\n",
      "Epoch 21/40\n",
      "656/656 [==============================] - 7s 11ms/step - loss: 0.1973 - accuracy: 0.9163\n",
      "Epoch 22/40\n",
      "656/656 [==============================] - 8s 12ms/step - loss: 0.1860 - accuracy: 0.9240\n",
      "Epoch 23/40\n",
      "656/656 [==============================] - 7s 11ms/step - loss: 0.1800 - accuracy: 0.9255\n",
      "Epoch 24/40\n",
      "656/656 [==============================] - 7s 10ms/step - loss: 0.1775 - accuracy: 0.9280\n",
      "Epoch 25/40\n",
      "656/656 [==============================] - 7s 11ms/step - loss: 0.1634 - accuracy: 0.9321\n",
      "Epoch 26/40\n",
      "656/656 [==============================] - 8s 12ms/step - loss: 0.1611 - accuracy: 0.9343\n",
      "Epoch 27/40\n",
      "656/656 [==============================] - 7s 11ms/step - loss: 0.1521 - accuracy: 0.9398\n",
      "Epoch 28/40\n",
      "656/656 [==============================] - 8s 12ms/step - loss: 0.1509 - accuracy: 0.9401\n",
      "Epoch 29/40\n",
      "656/656 [==============================] - 7s 11ms/step - loss: 0.1462 - accuracy: 0.9421\n",
      "Epoch 30/40\n",
      "656/656 [==============================] - 7s 11ms/step - loss: 0.1405 - accuracy: 0.9438\n",
      "Epoch 31/40\n",
      "656/656 [==============================] - 7s 11ms/step - loss: 0.1358 - accuracy: 0.9477\n",
      "Epoch 32/40\n",
      "656/656 [==============================] - 7s 10ms/step - loss: 0.1317 - accuracy: 0.9480\n",
      "Epoch 33/40\n",
      "656/656 [==============================] - 7s 11ms/step - loss: 0.1306 - accuracy: 0.9509\n",
      "Epoch 34/40\n",
      "656/656 [==============================] - 7s 11ms/step - loss: 0.1218 - accuracy: 0.9535\n",
      "Epoch 35/40\n",
      "656/656 [==============================] - 7s 11ms/step - loss: 0.1214 - accuracy: 0.9536\n",
      "Epoch 36/40\n",
      "656/656 [==============================] - 7s 11ms/step - loss: 0.1218 - accuracy: 0.9543\n",
      "Epoch 37/40\n",
      "656/656 [==============================] - 7s 11ms/step - loss: 0.1183 - accuracy: 0.9555\n",
      "Epoch 38/40\n",
      "656/656 [==============================] - 7s 11ms/step - loss: 0.1193 - accuracy: 0.9568\n",
      "Epoch 39/40\n",
      "656/656 [==============================] - 7s 11ms/step - loss: 0.1131 - accuracy: 0.9573\n",
      "Epoch 40/40\n",
      "656/656 [==============================] - 7s 10ms/step - loss: 0.1134 - accuracy: 0.9577\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create perturbed training set\n",
    "X_bim_perturbed_train = bim(5, epsilon, alpha, X_train, y_train)\n",
    "X_new_bim=np.concatenate((X_train,X_bim_perturbed_train))\n",
    "bim_stlstm=stacked_lstm(X_new_bim,new_Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model - BIM-StackedLSTM:\n",
      "Accuracy Score: 0.8251001335113485\n"
     ]
    }
   ],
   "source": [
    "\n",
    "stlstm_bim_predictions=get_result(bim_stlstm, X_test, y_test, \"BIM-StackedLSTM\")\n",
    "#plot_predictions(y_test, stlstm_bim_predictions, \"BIM-LSTM model (Clean)\", xLabel=\"Time\", yLabel=\"Power Consumption\", realLabel=\"Actual power consumption\", predictedLabel=\"Predicted power consumption\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model - BIM-StackedLSTM:\n",
      "Accuracy Score: 0.822429906542056\n"
     ]
    }
   ],
   "source": [
    "\n",
    "stlstm_bim_predictions=get_result(bim_stlstm, X_bim_perturbed_stlstm, y_test, \"BIM-StackedLSTM\")\n",
    "#plot_predictions(y_test, stlstm_bim_predictions, \"BIM-LSTM model (Perturbed)\", xLabel=\"Time\", yLabel=\"Power Consumption\", realLabel=\"Actual power consumption\", predictedLabel=\"Predicted power consumption\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_15 (LSTM)              (None, 14, 50)            10400     \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, 14, 50)            0         \n",
      "                                                                 \n",
      " lstm_16 (LSTM)              (None, 128)               91648     \n",
      "                                                                 \n",
      " dropout_20 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 102,177\n",
      "Trainable params: 102,177\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "656/656 [==============================] - 10s 11ms/step - loss: 0.6760 - accuracy: 0.5691\n",
      "Epoch 2/40\n",
      "656/656 [==============================] - 7s 11ms/step - loss: 0.6573 - accuracy: 0.6000\n",
      "Epoch 3/40\n",
      "656/656 [==============================] - 7s 11ms/step - loss: 0.6356 - accuracy: 0.6264\n",
      "Epoch 4/40\n",
      "656/656 [==============================] - 7s 11ms/step - loss: 0.6078 - accuracy: 0.6585\n",
      "Epoch 5/40\n",
      "656/656 [==============================] - 8s 12ms/step - loss: 0.5775 - accuracy: 0.6842\n",
      "Epoch 6/40\n",
      "656/656 [==============================] - 7s 11ms/step - loss: 0.5572 - accuracy: 0.6973\n",
      "Epoch 7/40\n",
      "656/656 [==============================] - 7s 10ms/step - loss: 0.5391 - accuracy: 0.7157\n",
      "Epoch 8/40\n",
      "656/656 [==============================] - 7s 10ms/step - loss: 0.5196 - accuracy: 0.7266\n",
      "Epoch 9/40\n",
      "656/656 [==============================] - 7s 10ms/step - loss: 0.5065 - accuracy: 0.7357\n",
      "Epoch 10/40\n",
      "656/656 [==============================] - 7s 11ms/step - loss: 0.4973 - accuracy: 0.7426\n",
      "Epoch 11/40\n",
      "656/656 [==============================] - 7s 10ms/step - loss: 0.4812 - accuracy: 0.7538\n",
      "Epoch 12/40\n",
      "656/656 [==============================] - 7s 11ms/step - loss: 0.4737 - accuracy: 0.7617\n",
      "Epoch 13/40\n",
      "656/656 [==============================] - 7s 10ms/step - loss: 0.4633 - accuracy: 0.7659\n",
      "Epoch 14/40\n",
      "656/656 [==============================] - 8s 12ms/step - loss: 0.4504 - accuracy: 0.7734\n",
      "Epoch 15/40\n",
      "656/656 [==============================] - 8s 13ms/step - loss: 0.4390 - accuracy: 0.7799\n",
      "Epoch 16/40\n",
      "656/656 [==============================] - 8s 12ms/step - loss: 0.4300 - accuracy: 0.7880\n",
      "Epoch 17/40\n",
      "656/656 [==============================] - 8s 12ms/step - loss: 0.4213 - accuracy: 0.7895\n",
      "Epoch 18/40\n",
      "656/656 [==============================] - 9s 13ms/step - loss: 0.4107 - accuracy: 0.7992\n",
      "Epoch 19/40\n",
      "656/656 [==============================] - 8s 12ms/step - loss: 0.4015 - accuracy: 0.8028\n",
      "Epoch 20/40\n",
      "656/656 [==============================] - 8s 12ms/step - loss: 0.3936 - accuracy: 0.8088\n",
      "Epoch 21/40\n",
      "656/656 [==============================] - 8s 12ms/step - loss: 0.3802 - accuracy: 0.8186\n",
      "Epoch 22/40\n",
      "656/656 [==============================] - 8s 12ms/step - loss: 0.3731 - accuracy: 0.8203\n",
      "Epoch 23/40\n",
      "656/656 [==============================] - 7s 11ms/step - loss: 0.3627 - accuracy: 0.8297\n",
      "Epoch 24/40\n",
      "656/656 [==============================] - 8s 12ms/step - loss: 0.3573 - accuracy: 0.8310\n",
      "Epoch 25/40\n",
      "656/656 [==============================] - 8s 12ms/step - loss: 0.3507 - accuracy: 0.8369\n",
      "Epoch 26/40\n",
      "656/656 [==============================] - 8s 12ms/step - loss: 0.3412 - accuracy: 0.8407\n",
      "Epoch 27/40\n",
      "656/656 [==============================] - 8s 12ms/step - loss: 0.3392 - accuracy: 0.8428\n",
      "Epoch 28/40\n",
      "656/656 [==============================] - 9s 13ms/step - loss: 0.3320 - accuracy: 0.8457\n",
      "Epoch 29/40\n",
      "656/656 [==============================] - 8s 13ms/step - loss: 0.3284 - accuracy: 0.8474\n",
      "Epoch 30/40\n",
      "656/656 [==============================] - 8s 12ms/step - loss: 0.3153 - accuracy: 0.8534\n",
      "Epoch 31/40\n",
      "656/656 [==============================] - 8s 12ms/step - loss: 0.3135 - accuracy: 0.8583\n",
      "Epoch 32/40\n",
      "656/656 [==============================] - 7s 11ms/step - loss: 0.3117 - accuracy: 0.8568\n",
      "Epoch 33/40\n",
      "656/656 [==============================] - 7s 11ms/step - loss: 0.3019 - accuracy: 0.8630\n",
      "Epoch 34/40\n",
      "656/656 [==============================] - 7s 11ms/step - loss: 0.3001 - accuracy: 0.8671\n",
      "Epoch 35/40\n",
      "656/656 [==============================] - 8s 12ms/step - loss: 0.2910 - accuracy: 0.8703\n",
      "Epoch 36/40\n",
      "656/656 [==============================] - 7s 11ms/step - loss: 0.2921 - accuracy: 0.8714\n",
      "Epoch 37/40\n",
      "656/656 [==============================] - 8s 12ms/step - loss: 0.2819 - accuracy: 0.8764\n",
      "Epoch 38/40\n",
      "656/656 [==============================] - 8s 12ms/step - loss: 0.2847 - accuracy: 0.8718\n",
      "Epoch 39/40\n",
      "656/656 [==============================] - 8s 12ms/step - loss: 0.2850 - accuracy: 0.8729\n",
      "Epoch 40/40\n",
      "656/656 [==============================] - 8s 12ms/step - loss: 0.2740 - accuracy: 0.8812\n"
     ]
    }
   ],
   "source": [
    "# Create perturbed training set\n",
    "X_pgd_perturbed_train = pgd(5, epsilon, alpha, X_train, y_train)\n",
    "X_new_pgd=np.concatenate((X_train,X_pgd_perturbed_train))\n",
    "pgd_stlstm=stacked_lstm(X_new_pgd,new_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model - PGD-StackedLSTM:\n",
      "Accuracy Score: 0.8277703604806409\n"
     ]
    }
   ],
   "source": [
    "stlstm_pgd_predictions=get_result(pgd_stlstm, X_test, y_test, \"PGD-StackedLSTM\")\n",
    "#plot_predictions(y_test, stlstm_pgd_predictions, \"PGD-LSTM model (Clean)\", xLabel=\"Time\", yLabel=\"Power Consumption\", realLabel=\"Actual power consumption\", predictedLabel=\"Predicted power consumption\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model - PGD-StackedLSTM:\n",
      "Accuracy Score: 0.7053849577214063\n"
     ]
    }
   ],
   "source": [
    "stlstm_pgd_predictions=get_result(pgd_stlstm, X_pgd_perturbed_stlstm, y_test, \"PGD-StackedLSTM\")\n",
    "#plot_predictions(y_test, stlstm_pgd_predictions, \"PGD-LSTM model (Perturbed)\", xLabel=\"Time\", yLabel=\"Power Consumption\", realLabel=\"Actual power consumption\", predictedLabel=\"Predicted power consumption\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_2 (GRU)                 (None, 50)                7950      \n",
      "                                                                 \n",
      " dropout_21 (Dropout)        (None, 50)                0         \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,001\n",
      "Trainable params: 8,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "656/656 [==============================] - 5s 5ms/step - loss: 0.6715 - accuracy: 0.5789\n",
      "Epoch 2/40\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.6417 - accuracy: 0.6227\n",
      "Epoch 3/40\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.5970 - accuracy: 0.6660\n",
      "Epoch 4/40\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.5735 - accuracy: 0.6907\n",
      "Epoch 5/40\n",
      "656/656 [==============================] - 3s 5ms/step - loss: 0.5439 - accuracy: 0.7165\n",
      "Epoch 6/40\n",
      "656/656 [==============================] - 3s 5ms/step - loss: 0.5111 - accuracy: 0.7416\n",
      "Epoch 7/40\n",
      "656/656 [==============================] - 3s 5ms/step - loss: 0.4892 - accuracy: 0.7567\n",
      "Epoch 8/40\n",
      "656/656 [==============================] - 3s 5ms/step - loss: 0.4723 - accuracy: 0.7687: 0s - loss: 0.4722 - ac\n",
      "Epoch 9/40\n",
      "656/656 [==============================] - 3s 5ms/step - loss: 0.4537 - accuracy: 0.7773\n",
      "Epoch 10/40\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.4413 - accuracy: 0.7847\n",
      "Epoch 11/40\n",
      "656/656 [==============================] - 3s 5ms/step - loss: 0.4277 - accuracy: 0.7941\n",
      "Epoch 12/40\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.4161 - accuracy: 0.7992\n",
      "Epoch 13/40\n",
      "656/656 [==============================] - 3s 5ms/step - loss: 0.4061 - accuracy: 0.8086\n",
      "Epoch 14/40\n",
      "656/656 [==============================] - 3s 5ms/step - loss: 0.3959 - accuracy: 0.8129\n",
      "Epoch 15/40\n",
      "656/656 [==============================] - 3s 5ms/step - loss: 0.3939 - accuracy: 0.8133\n",
      "Epoch 16/40\n",
      "656/656 [==============================] - 3s 5ms/step - loss: 0.3844 - accuracy: 0.8182\n",
      "Epoch 17/40\n",
      "656/656 [==============================] - 3s 5ms/step - loss: 0.3820 - accuracy: 0.8225\n",
      "Epoch 18/40\n",
      "656/656 [==============================] - 3s 5ms/step - loss: 0.3728 - accuracy: 0.8286\n",
      "Epoch 19/40\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.3721 - accuracy: 0.8278\n",
      "Epoch 20/40\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.3620 - accuracy: 0.8318\n",
      "Epoch 21/40\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.3577 - accuracy: 0.8351\n",
      "Epoch 22/40\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.3565 - accuracy: 0.8352\n",
      "Epoch 23/40\n",
      "656/656 [==============================] - 3s 5ms/step - loss: 0.3508 - accuracy: 0.8391\n",
      "Epoch 24/40\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.3432 - accuracy: 0.8420\n",
      "Epoch 25/40\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.3445 - accuracy: 0.8432\n",
      "Epoch 26/40\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.3438 - accuracy: 0.8427\n",
      "Epoch 27/40\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.3360 - accuracy: 0.8479\n",
      "Epoch 28/40\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.3357 - accuracy: 0.8466\n",
      "Epoch 29/40\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.3335 - accuracy: 0.8478\n",
      "Epoch 30/40\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.3323 - accuracy: 0.8481\n",
      "Epoch 31/40\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.3260 - accuracy: 0.8500\n",
      "Epoch 32/40\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.3214 - accuracy: 0.8550\n",
      "Epoch 33/40\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.3229 - accuracy: 0.8516\n",
      "Epoch 34/40\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.3211 - accuracy: 0.8543\n",
      "Epoch 35/40\n",
      "656/656 [==============================] - 3s 5ms/step - loss: 0.3172 - accuracy: 0.8538\n",
      "Epoch 36/40\n",
      "656/656 [==============================] - 3s 5ms/step - loss: 0.3193 - accuracy: 0.8541\n",
      "Epoch 37/40\n",
      "656/656 [==============================] - 3s 5ms/step - loss: 0.3183 - accuracy: 0.8545\n",
      "Epoch 38/40\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.3124 - accuracy: 0.8583\n",
      "Epoch 39/40\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.3101 - accuracy: 0.8590\n",
      "Epoch 40/40\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.3128 - accuracy: 0.8593: 0s - loss: 0.3129 - accuracy: \n"
     ]
    }
   ],
   "source": [
    "# Create perturbed training set\n",
    "X_fgsm_perturbed_train = fgsm(X_train, y_train, epsilon)\n",
    "X_new_gru=np.concatenate((X_train,X_fgsm_perturbed_train))\n",
    "fgsm_gru=gru(X_new_gru,new_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model - FGSM-GRU:\n",
      "Accuracy Score: 0.8164218958611482\n"
     ]
    }
   ],
   "source": [
    "gru_fgsm_predictions=get_result(fgsm_gru, X_test, y_test, \"FGSM-GRU\")\n",
    "#plot_predictions(y_test, gru_fgsm_predictions, \"FGSM-GRU model (Clean)\", xLabel=\"Time\", yLabel=\"Power Consumption\", realLabel=\"Actual power consumption\", predictedLabel=\"Predicted power consumption\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model - FGSM-StackedLSTM:\n",
      "Accuracy Score: 0.8079661771250556\n"
     ]
    }
   ],
   "source": [
    "gru_fgsm_predictions=get_result(fgsm_gru, X_fgsm_perturbed_gru, y_test, \"FGSM-StackedLSTM\")\n",
    "#plot_predictions(y_test, gru_fgsm_predictions, \"FGSM-LSTM model (Perturbed)\", xLabel=\"Time\", yLabel=\"Power Consumption\", realLabel=\"Actual power consumption\", predictedLabel=\"Predicted power consumption\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_3 (GRU)                 (None, 50)                7950      \n",
      "                                                                 \n",
      " dropout_22 (Dropout)        (None, 50)                0         \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,001\n",
      "Trainable params: 8,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "656/656 [==============================] - 5s 5ms/step - loss: 0.6685 - accuracy: 0.5829: 0s - loss: 0.673\n",
      "Epoch 2/40\n",
      "656/656 [==============================] - 3s 5ms/step - loss: 0.6212 - accuracy: 0.6360\n",
      "Epoch 3/40\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.5883 - accuracy: 0.6695\n",
      "Epoch 4/40\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.5608 - accuracy: 0.6935\n",
      "Epoch 5/40\n",
      "656/656 [==============================] - 3s 5ms/step - loss: 0.5324 - accuracy: 0.7184\n",
      "Epoch 6/40\n",
      "656/656 [==============================] - 3s 5ms/step - loss: 0.5085 - accuracy: 0.7402\n",
      "Epoch 7/40\n",
      "656/656 [==============================] - 3s 5ms/step - loss: 0.4805 - accuracy: 0.7599\n",
      "Epoch 8/40\n",
      "656/656 [==============================] - 3s 5ms/step - loss: 0.4561 - accuracy: 0.7776\n",
      "Epoch 9/40\n",
      "656/656 [==============================] - 3s 5ms/step - loss: 0.4398 - accuracy: 0.7836\n",
      "Epoch 10/40\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.4232 - accuracy: 0.7954\n",
      "Epoch 11/40\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.4096 - accuracy: 0.8053\n",
      "Epoch 12/40\n",
      "656/656 [==============================] - 3s 5ms/step - loss: 0.3984 - accuracy: 0.8134\n",
      "Epoch 13/40\n",
      "656/656 [==============================] - 3s 5ms/step - loss: 0.3861 - accuracy: 0.8203\n",
      "Epoch 14/40\n",
      "656/656 [==============================] - 3s 5ms/step - loss: 0.3781 - accuracy: 0.8229\n",
      "Epoch 15/40\n",
      "656/656 [==============================] - 3s 5ms/step - loss: 0.3676 - accuracy: 0.8281\n",
      "Epoch 16/40\n",
      "656/656 [==============================] - 3s 5ms/step - loss: 0.3633 - accuracy: 0.8310\n",
      "Epoch 17/40\n",
      "656/656 [==============================] - 3s 5ms/step - loss: 0.3562 - accuracy: 0.8325\n",
      "Epoch 18/40\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.3450 - accuracy: 0.8382\n",
      "Epoch 19/40\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.3418 - accuracy: 0.8431\n",
      "Epoch 20/40\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.3372 - accuracy: 0.8466\n",
      "Epoch 21/40\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.3363 - accuracy: 0.8456\n",
      "Epoch 22/40\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.3244 - accuracy: 0.8512\n",
      "Epoch 23/40\n",
      "656/656 [==============================] - 3s 5ms/step - loss: 0.3190 - accuracy: 0.8554\n",
      "Epoch 24/40\n",
      "656/656 [==============================] - 3s 5ms/step - loss: 0.3151 - accuracy: 0.8543\n",
      "Epoch 25/40\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.3098 - accuracy: 0.8566\n",
      "Epoch 26/40\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.3060 - accuracy: 0.8623\n",
      "Epoch 27/40\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.3033 - accuracy: 0.8635\n",
      "Epoch 28/40\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.3032 - accuracy: 0.8649\n",
      "Epoch 29/40\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.2981 - accuracy: 0.8656\n",
      "Epoch 30/40\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.2955 - accuracy: 0.8677\n",
      "Epoch 31/40\n",
      "656/656 [==============================] - 3s 5ms/step - loss: 0.2944 - accuracy: 0.8689\n",
      "Epoch 32/40\n",
      "656/656 [==============================] - 3s 5ms/step - loss: 0.2857 - accuracy: 0.8705\n",
      "Epoch 33/40\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.2884 - accuracy: 0.8692\n",
      "Epoch 34/40\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.2799 - accuracy: 0.8744\n",
      "Epoch 35/40\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.2825 - accuracy: 0.8734\n",
      "Epoch 36/40\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.2744 - accuracy: 0.8788\n",
      "Epoch 37/40\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.2739 - accuracy: 0.8780\n",
      "Epoch 38/40\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.2744 - accuracy: 0.8803\n",
      "Epoch 39/40\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.2757 - accuracy: 0.8761\n",
      "Epoch 40/40\n",
      "656/656 [==============================] - 3s 5ms/step - loss: 0.2719 - accuracy: 0.8796\n"
     ]
    }
   ],
   "source": [
    "# Create perturbed training set\n",
    "X_bim_perturbed_train = bim(5, epsilon, alpha, X_train, y_train)\n",
    "X_new_gru=np.concatenate((X_train,X_bim_perturbed_train))\n",
    "bim_gru=gru(X_new_gru,new_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model - BIM-GRU:\n",
      "Accuracy Score: 0.8097463284379173\n"
     ]
    }
   ],
   "source": [
    "gru_bim_predictions=get_result(bim_gru, X_test, y_test, \"BIM-GRU\")\n",
    "#plot_predictions(y_test, gru_bim_predictions, \"BIM-GRU model (Clean)\", xLabel=\"Time\", yLabel=\"Power Consumption\", realLabel=\"Actual power consumption\", predictedLabel=\"Predicted power consumption\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model - BIM-GRU:\n",
      "Accuracy Score: 0.8104138851802403\n"
     ]
    }
   ],
   "source": [
    "gru_bim_predictions=get_result(bim_gru, X_bim_perturbed_gru, y_test, \"BIM-GRU\")\n",
    "#plot_predictions(y_test, gru_bim_predictions, \"BIM-GRU model (Perturbed)\", xLabel=\"Time\", yLabel=\"Power Consumption\", realLabel=\"Actual power consumption\", predictedLabel=\"Predicted power consumption\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_5 (GRU)                 (None, 50)                7950      \n",
      "                                                                 \n",
      " dropout_24 (Dropout)        (None, 50)                0         \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,001\n",
      "Trainable params: 8,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "656/656 [==============================] - 7s 5ms/step - loss: 0.6727 - accuracy: 0.5751\n",
      "Epoch 2/40\n",
      "656/656 [==============================] - 3s 5ms/step - loss: 0.6481 - accuracy: 0.6074\n",
      "Epoch 3/40\n",
      "656/656 [==============================] - 3s 5ms/step - loss: 0.6302 - accuracy: 0.6296\n",
      "Epoch 4/40\n",
      "656/656 [==============================] - 4s 5ms/step - loss: 0.6135 - accuracy: 0.6458\n",
      "Epoch 5/40\n",
      "656/656 [==============================] - 3s 5ms/step - loss: 0.5981 - accuracy: 0.6623\n",
      "Epoch 6/40\n",
      "656/656 [==============================] - 4s 5ms/step - loss: 0.5815 - accuracy: 0.6740\n",
      "Epoch 7/40\n",
      "656/656 [==============================] - 3s 5ms/step - loss: 0.5682 - accuracy: 0.6881\n",
      "Epoch 8/40\n",
      "656/656 [==============================] - 3s 5ms/step - loss: 0.5548 - accuracy: 0.7052\n",
      "Epoch 9/40\n",
      "656/656 [==============================] - 3s 5ms/step - loss: 0.5441 - accuracy: 0.7094\n",
      "Epoch 10/40\n",
      "656/656 [==============================] - 4s 5ms/step - loss: 0.5334 - accuracy: 0.7170\n",
      "Epoch 11/40\n",
      "656/656 [==============================] - 3s 5ms/step - loss: 0.5267 - accuracy: 0.7218\n",
      "Epoch 12/40\n",
      "656/656 [==============================] - 3s 5ms/step - loss: 0.5189 - accuracy: 0.7281\n",
      "Epoch 13/40\n",
      "656/656 [==============================] - 3s 5ms/step - loss: 0.5131 - accuracy: 0.7331\n",
      "Epoch 14/40\n",
      "656/656 [==============================] - 3s 5ms/step - loss: 0.5064 - accuracy: 0.7375\n",
      "Epoch 15/40\n",
      "656/656 [==============================] - 3s 5ms/step - loss: 0.5029 - accuracy: 0.7401\n",
      "Epoch 16/40\n",
      "656/656 [==============================] - 3s 5ms/step - loss: 0.4976 - accuracy: 0.7427\n",
      "Epoch 17/40\n",
      "656/656 [==============================] - 3s 5ms/step - loss: 0.4870 - accuracy: 0.7498\n",
      "Epoch 18/40\n",
      "656/656 [==============================] - 3s 5ms/step - loss: 0.4860 - accuracy: 0.7532\n",
      "Epoch 19/40\n",
      "656/656 [==============================] - 3s 5ms/step - loss: 0.4803 - accuracy: 0.7559\n",
      "Epoch 20/40\n",
      "656/656 [==============================] - 4s 5ms/step - loss: 0.4761 - accuracy: 0.7609\n",
      "Epoch 21/40\n",
      "656/656 [==============================] - 3s 5ms/step - loss: 0.4740 - accuracy: 0.7566\n",
      "Epoch 22/40\n",
      "656/656 [==============================] - 3s 5ms/step - loss: 0.4681 - accuracy: 0.7645\n",
      "Epoch 23/40\n",
      "656/656 [==============================] - 3s 5ms/step - loss: 0.4660 - accuracy: 0.7658\n",
      "Epoch 24/40\n",
      "656/656 [==============================] - 4s 6ms/step - loss: 0.4611 - accuracy: 0.7679\n",
      "Epoch 25/40\n",
      "656/656 [==============================] - 3s 5ms/step - loss: 0.4610 - accuracy: 0.7700\n",
      "Epoch 26/40\n",
      "656/656 [==============================] - 3s 5ms/step - loss: 0.4572 - accuracy: 0.7693\n",
      "Epoch 27/40\n",
      "656/656 [==============================] - 3s 5ms/step - loss: 0.4583 - accuracy: 0.7696\n",
      "Epoch 28/40\n",
      "656/656 [==============================] - 3s 5ms/step - loss: 0.4514 - accuracy: 0.7760\n",
      "Epoch 29/40\n",
      "656/656 [==============================] - 3s 5ms/step - loss: 0.4508 - accuracy: 0.7721\n",
      "Epoch 30/40\n",
      "656/656 [==============================] - 3s 5ms/step - loss: 0.4494 - accuracy: 0.7759\n",
      "Epoch 31/40\n",
      "656/656 [==============================] - 3s 5ms/step - loss: 0.4470 - accuracy: 0.7787\n",
      "Epoch 32/40\n",
      "656/656 [==============================] - 3s 5ms/step - loss: 0.4437 - accuracy: 0.7831\n",
      "Epoch 33/40\n",
      "656/656 [==============================] - 3s 5ms/step - loss: 0.4447 - accuracy: 0.7803\n",
      "Epoch 34/40\n",
      "656/656 [==============================] - 4s 5ms/step - loss: 0.4396 - accuracy: 0.7820\n",
      "Epoch 35/40\n",
      "656/656 [==============================] - 3s 5ms/step - loss: 0.4332 - accuracy: 0.7865\n",
      "Epoch 36/40\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.4407 - accuracy: 0.7819\n",
      "Epoch 37/40\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.4373 - accuracy: 0.7836\n",
      "Epoch 38/40\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.4314 - accuracy: 0.7850\n",
      "Epoch 39/40\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.4342 - accuracy: 0.7856\n",
      "Epoch 40/40\n",
      "656/656 [==============================] - 3s 5ms/step - loss: 0.4296 - accuracy: 0.7889\n"
     ]
    }
   ],
   "source": [
    "# Create perturbed training set\n",
    "X_pgd_perturbed_train = pgd(5, epsilon, alpha, X_train, y_train)\n",
    "X_new_gru=np.concatenate((X_train,X_pgd_perturbed_train))\n",
    "pgd_gru=gru(X_new_gru,new_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model - PGD-GRU:\n",
      "Accuracy Score: 0.7890520694259012\n"
     ]
    }
   ],
   "source": [
    "gru_pgd_predictions=get_result(pgd_gru, X_test, y_test, \"PGD-GRU\")\n",
    "#plot_predictions(y_test, gru_pgd_predictions, \"PGD-GRU model (Clean)\", xLabel=\"Time\", yLabel=\"Power Consumption\", realLabel=\"Actual power consumption\", predictedLabel=\"Predicted power consumption\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model - PGD-GRU:\n",
      "Accuracy Score: 0.6477525589675123\n"
     ]
    }
   ],
   "source": [
    "gru_pgd_predictions=get_result(pgd_gru, X_pgd_perturbed_gru, y_test, \"PGD-GRU\")\n",
    "#plot_predictions(y_test, gru_pgd_predictions, \"PGD-GRU model (Perturbed)\", xLabel=\"Time\", yLabel=\"Power Consumption\", realLabel=\"Actual power consumption\", predictedLabel=\"Predicted power consumption\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-24 00:31:08.895591: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 6156372600 exceeds 10% of free system memory.\n",
      "2022-04-24 00:31:10.577449: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 6156372600 exceeds 10% of free system memory.\n",
      "2022-04-24 00:31:11.444821: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 6156372600 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "# Create perturbed training set\n",
    "X_fgsm_perturbed_train = fgsm(X_train, y_train)\n",
    "X_new_rnn=np.concatenate((X_train,X_fgsm_perturbed_train))\n",
    "fgsm_rnn=rnn(X_new_rnn,new_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model - FGSM-RNN:\n",
      "Accuracy Score: 0.5747663551401869\n"
     ]
    }
   ],
   "source": [
    "rnn_fgsm_predictions=get_result(fgsm_rnn, X_test, y_test, \"FGSM-RNN\")\n",
    "#plot_predictions(y_test, rnn_fgsm_predictions, \"FGSM-RNN model (Clean)\", xLabel=\"Time\", yLabel=\"Power Consumption\", realLabel=\"Actual power consumption\", predictedLabel=\"Predicted power consumption\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model - FGSM-RNN:\n",
      "Accuracy Score: 0.5609701824655096\n"
     ]
    }
   ],
   "source": [
    "rnn_fgsm_predictions=get_result(fgsm_rnn, X_fgsm_perturbed_rnn, y_test, \"FGSM-RNN\")\n",
    "#plot_predictions(y_test, rnn_fgsm_predictions, \"FGSM-RNN model (Perturbed)\", xLabel=\"Time\", yLabel=\"Power Consumption\", realLabel=\"Actual power consumption\", predictedLabel=\"Predicted power consumption\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_35\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_5 (SimpleRNN)    (None, 50)                2600      \n",
      "                                                                 \n",
      " dropout_27 (Dropout)        (None, 50)                0         \n",
      "                                                                 \n",
      " dense_51 (Dense)            (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,651\n",
      "Trainable params: 2,651\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "656/656 [==============================] - 9s 3ms/step - loss: 0.6758 - accuracy: 0.5692\n",
      "Epoch 2/40\n",
      "656/656 [==============================] - 2s 4ms/step - loss: 0.6654 - accuracy: 0.5835\n",
      "Epoch 3/40\n",
      "656/656 [==============================] - 2s 4ms/step - loss: 0.6600 - accuracy: 0.5961\n",
      "Epoch 4/40\n",
      "656/656 [==============================] - 2s 3ms/step - loss: 0.6240 - accuracy: 0.6393\n",
      "Epoch 5/40\n",
      "656/656 [==============================] - 2s 3ms/step - loss: 0.6019 - accuracy: 0.6580\n",
      "Epoch 6/40\n",
      "656/656 [==============================] - 2s 4ms/step - loss: 0.5881 - accuracy: 0.6738\n",
      "Epoch 7/40\n",
      "656/656 [==============================] - 3s 5ms/step - loss: 0.5705 - accuracy: 0.6979\n",
      "Epoch 8/40\n",
      "656/656 [==============================] - 3s 5ms/step - loss: 0.5655 - accuracy: 0.6969\n",
      "Epoch 9/40\n",
      "656/656 [==============================] - 3s 5ms/step - loss: 0.5649 - accuracy: 0.6957\n",
      "Epoch 10/40\n",
      "656/656 [==============================] - 3s 5ms/step - loss: 0.5612 - accuracy: 0.7005\n",
      "Epoch 11/40\n",
      "656/656 [==============================] - 2s 3ms/step - loss: 0.5598 - accuracy: 0.7046\n",
      "Epoch 12/40\n",
      "656/656 [==============================] - 2s 3ms/step - loss: 0.5631 - accuracy: 0.6971\n",
      "Epoch 13/40\n",
      "656/656 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.6969\n",
      "Epoch 14/40\n",
      "656/656 [==============================] - 2s 4ms/step - loss: 0.5673 - accuracy: 0.6955\n",
      "Epoch 15/40\n",
      "656/656 [==============================] - 2s 3ms/step - loss: 0.5783 - accuracy: 0.6790\n",
      "Epoch 16/40\n",
      "656/656 [==============================] - 2s 3ms/step - loss: 0.5912 - accuracy: 0.6719\n",
      "Epoch 17/40\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.5786 - accuracy: 0.6854\n",
      "Epoch 18/40\n",
      "656/656 [==============================] - 3s 5ms/step - loss: 0.6025 - accuracy: 0.6645\n",
      "Epoch 19/40\n",
      "656/656 [==============================] - 4s 6ms/step - loss: 0.5983 - accuracy: 0.6655\n",
      "Epoch 20/40\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.5989 - accuracy: 0.6653\n",
      "Epoch 21/40\n",
      "656/656 [==============================] - 2s 3ms/step - loss: 0.6173 - accuracy: 0.6486\n",
      "Epoch 22/40\n",
      "656/656 [==============================] - 2s 3ms/step - loss: 0.6206 - accuracy: 0.6397\n",
      "Epoch 23/40\n",
      "656/656 [==============================] - 2s 3ms/step - loss: 0.6177 - accuracy: 0.6428\n",
      "Epoch 24/40\n",
      "656/656 [==============================] - 3s 5ms/step - loss: 0.6536 - accuracy: 0.6096\n",
      "Epoch 25/40\n",
      "656/656 [==============================] - 5s 7ms/step - loss: 0.6648 - accuracy: 0.5867\n",
      "Epoch 26/40\n",
      "656/656 [==============================] - 3s 5ms/step - loss: 0.6554 - accuracy: 0.5994\n",
      "Epoch 27/40\n",
      "656/656 [==============================] - 2s 3ms/step - loss: 0.6593 - accuracy: 0.5929\n",
      "Epoch 28/40\n",
      "656/656 [==============================] - 3s 5ms/step - loss: 0.6741 - accuracy: 0.5726\n",
      "Epoch 29/40\n",
      "656/656 [==============================] - 2s 4ms/step - loss: 0.6722 - accuracy: 0.5773\n",
      "Epoch 30/40\n",
      "656/656 [==============================] - 4s 6ms/step - loss: 0.6751 - accuracy: 0.5714\n",
      "Epoch 31/40\n",
      "656/656 [==============================] - 3s 5ms/step - loss: 0.6674 - accuracy: 0.5843\n",
      "Epoch 32/40\n",
      "656/656 [==============================] - 4s 6ms/step - loss: 0.6695 - accuracy: 0.5806\n",
      "Epoch 33/40\n",
      "656/656 [==============================] - 3s 5ms/step - loss: 0.6761 - accuracy: 0.5741\n",
      "Epoch 34/40\n",
      "656/656 [==============================] - 2s 3ms/step - loss: 0.6752 - accuracy: 0.5719\n",
      "Epoch 35/40\n",
      "656/656 [==============================] - 2s 3ms/step - loss: 0.6745 - accuracy: 0.5742\n",
      "Epoch 36/40\n",
      "656/656 [==============================] - 2s 3ms/step - loss: 0.6757 - accuracy: 0.5739\n",
      "Epoch 37/40\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.6805 - accuracy: 0.5670\n",
      "Epoch 38/40\n",
      "656/656 [==============================] - 3s 5ms/step - loss: 0.6777 - accuracy: 0.5724\n",
      "Epoch 39/40\n",
      "656/656 [==============================] - 4s 6ms/step - loss: 0.6763 - accuracy: 0.5722\n",
      "Epoch 40/40\n",
      "656/656 [==============================] - 2s 3ms/step - loss: 0.6782 - accuracy: 0.5703\n"
     ]
    }
   ],
   "source": [
    "# Create perturbed training set\n",
    "X_bim_perturbed_train = bim(5, epsilon, alpha, X_train, y_train)\n",
    "X_new_rnn=np.concatenate((X_train,X_bim_perturbed_train))\n",
    "bim_rnn=rnn(X_new_rnn,new_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model - BIM-RNN:\n",
      "Accuracy Score: 0.5607476635514018\n"
     ]
    }
   ],
   "source": [
    "rnn_bim_predictions=get_result(bim_rnn, X_test, y_test, \"BIM-RNN\")\n",
    "#plot_predictions(y_test, rnn_bim_predictions, \"BIM-RNN model (Clean)\", xLabel=\"Time\", yLabel=\"Power Consumption\", realLabel=\"Actual power consumption\", predictedLabel=\"Predicted power consumption\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model - BIM-RNN:\n",
      "Accuracy Score: 0.557632398753894\n"
     ]
    }
   ],
   "source": [
    "rnn_bim_predictions=get_result(bim_rnn, X_bim_perturbed_rnn, y_test, \"BIM-RNN\")\n",
    "#plot_predictions(y_test, rnn_bim_predictions, \"BIM-RNN model (Perturbed)\", xLabel=\"Time\", yLabel=\"Power Consumption\", realLabel=\"Actual power consumption\", predictedLabel=\"Predicted power consumption\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Create perturbed training set\n",
    "X_pgd_perturbed_train = pgd(5, epsilon, alpha, X_train, y_train)\n",
    "X_new_rnn=np.concatenate((X_train,X_pgd_perturbed_train))\n",
    "pgd_rnn=rnn(X_new_rnn,new_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model - PGD-RNN:\n",
      "Accuracy Score: 0.47085002225189143\n"
     ]
    }
   ],
   "source": [
    "rnn_pgd_predictions=get_result(pgd_rnn, X_test, y_test, \"PGD-RNN\")\n",
    "#plot_predictions(y_test, rnn_pgd_predictions, \"PGD-RNN model (Clean)\", xLabel=\"Time\", yLabel=\"Power Consumption\", realLabel=\"Actual power consumption\", predictedLabel=\"Predicted power consumption\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model - PGD-RNN:\n",
      "Accuracy Score: 0.4744103248776146\n"
     ]
    }
   ],
   "source": [
    "rnn_pgd_predictions=get_result(pgd_rnn, X_pgd_perturbed_rnn, y_test, \"PGD-RNN\")\n",
    "#plot_predictions(y_test, rnn_pgd_predictions, \"PGD-RNN model (Perturbed)\", xLabel=\"Time\", yLabel=\"Power Consumption\", realLabel=\"Actual power consumption\", predictedLabel=\"Predicted power consumption\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_2 (Conv1D)           (None, 12, 64)            256       \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPooling  (None, 4, 64)            0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 30)                7710      \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 10)                310       \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,287\n",
      "Trainable params: 8,287\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "656/656 [==============================] - 2s 2ms/step - loss: 0.2790\n",
      "Epoch 2/50\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2447\n",
      "Epoch 3/50\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2375\n",
      "Epoch 4/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.2258A: \n",
      "Epoch 5/50\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2164\n",
      "Epoch 6/50\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.4154\n",
      "Epoch 7/50\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2552\n",
      "Epoch 8/50\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2959\n",
      "Epoch 9/50\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.3067\n",
      "Epoch 10/50\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2146\n",
      "Epoch 11/50\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2122\n",
      "Epoch 12/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.2080\n",
      "Epoch 13/50\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2505\n",
      "Epoch 14/50\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2475\n",
      "Epoch 15/50\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2019\n",
      "Epoch 16/50\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.1964\n",
      "Epoch 17/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1923\n",
      "Epoch 18/50\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.1894\n",
      "Epoch 19/50\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.1855\n",
      "Epoch 20/50\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.1828\n",
      "Epoch 21/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1861\n",
      "Epoch 22/50\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.1787\n",
      "Epoch 23/50\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.1752\n",
      "Epoch 24/50\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.1739\n",
      "Epoch 25/50\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.1717\n",
      "Epoch 26/50\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.1716\n",
      "Epoch 27/50\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.1731\n",
      "Epoch 28/50\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.1661\n",
      "Epoch 29/50\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.1643\n",
      "Epoch 30/50\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.1624\n",
      "Epoch 31/50\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.1609\n",
      "Epoch 32/50\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.1595\n",
      "Epoch 33/50\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.1575\n",
      "Epoch 34/50\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.1561\n",
      "Epoch 35/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1559\n",
      "Epoch 36/50\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.1862\n",
      "Epoch 37/50\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.1565A: 0s - \n",
      "Epoch 38/50\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.1524\n",
      "Epoch 39/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1519\n",
      "Epoch 40/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1557\n",
      "Epoch 41/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1630\n",
      "Epoch 42/50\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.1507\n",
      "Epoch 43/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1486\n",
      "Epoch 44/50\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.1550A: 0s - loss: 0\n",
      "Epoch 45/50\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.1890\n",
      "Epoch 46/50\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.1482\n",
      "Epoch 47/50\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.1466\n",
      "Epoch 48/50\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.1470\n",
      "Epoch 49/50\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.1724\n",
      "Epoch 50/50\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.1534\n"
     ]
    }
   ],
   "source": [
    "# Create perturbed training set\n",
    "X_fgsm_perturbed_train = fgsm(X_train, y_train, epsilon)\n",
    "X_new_cnn=np.concatenate((X_train,X_fgsm_perturbed_train))\n",
    "fgsm_cnn=cnn(X_new_cnn,new_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model - FGSM-CNN:\n",
      "Accuracy Score: 0.7857142857142857\n"
     ]
    }
   ],
   "source": [
    "cnn_fgsm_predictions=get_result(fgsm_cnn, X_test, y_test, \"FGSM-CNN\")\n",
    "#plot_predictions(y_test, cnn_fgsm_predictions, \"FGSM-CNN model (Clean)\", xLabel=\"Time\", yLabel=\"Power Consumption\", realLabel=\"Actual power consumption\", predictedLabel=\"Predicted power consumption\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model - FGSM-CNN:\n",
      "Accuracy Score: 0.7792612372051625\n"
     ]
    }
   ],
   "source": [
    "cnn_fgsm_predictions=get_result(fgsm_cnn, X_fgsm_perturbed_cnn, y_test, \"FGSM-CNN\")\n",
    "#plot_predictions(y_test, cnn_fgsm_predictions, \"FGSM-CNN model (Perturbed)\", xLabel=\"Time\", yLabel=\"Power Consumption\", realLabel=\"Actual power consumption\", predictedLabel=\"Predicted power consumption\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_3 (Conv1D)           (None, 12, 64)            256       \n",
      "                                                                 \n",
      " max_pooling1d_3 (MaxPooling  (None, 4, 64)            0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 30)                7710      \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 10)                310       \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,287\n",
      "Trainable params: 8,287\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "656/656 [==============================] - 2s 1ms/step - loss: 0.2878A: 0s - loss: 0\n",
      "Epoch 2/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.2388\n",
      "Epoch 3/50\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2345\n",
      "Epoch 4/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.2299\n",
      "Epoch 5/50\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2255\n",
      "Epoch 6/50\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2213\n",
      "Epoch 7/50\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2170\n",
      "Epoch 8/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.2124\n",
      "Epoch 9/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.2072\n",
      "Epoch 10/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.2033\n",
      "Epoch 11/50\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2005\n",
      "Epoch 12/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1974\n",
      "Epoch 13/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1954\n",
      "Epoch 14/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1933\n",
      "Epoch 15/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1921\n",
      "Epoch 16/50\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.1914\n",
      "Epoch 17/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1888\n",
      "Epoch 18/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1870\n",
      "Epoch 19/50\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.1854\n",
      "Epoch 20/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1806\n",
      "Epoch 21/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1783\n",
      "Epoch 22/50\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.1807\n",
      "Epoch 23/50\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.1727\n",
      "Epoch 24/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1705\n",
      "Epoch 25/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1685\n",
      "Epoch 26/50\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.1679\n",
      "Epoch 27/50\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.1662\n",
      "Epoch 28/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1651\n",
      "Epoch 29/50\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.1640\n",
      "Epoch 30/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1620\n",
      "Epoch 31/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1614\n",
      "Epoch 32/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1595\n",
      "Epoch 33/50\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.1577\n",
      "Epoch 34/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1577\n",
      "Epoch 35/50\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.1571\n",
      "Epoch 36/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1567\n",
      "Epoch 37/50\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.1534\n",
      "Epoch 38/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1535\n",
      "Epoch 39/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1524\n",
      "Epoch 40/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1517\n",
      "Epoch 41/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1521\n",
      "Epoch 42/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1506\n",
      "Epoch 43/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1496\n",
      "Epoch 44/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1490\n",
      "Epoch 45/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1495\n",
      "Epoch 46/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1485\n",
      "Epoch 47/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1468A: 0s - loss:  - ETA: 0s - los\n",
      "Epoch 48/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1462\n",
      "Epoch 49/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1449\n",
      "Epoch 50/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1450\n"
     ]
    }
   ],
   "source": [
    "# Create perturbed training set\n",
    "X_bim_perturbed_train = bim(5, epsilon, alpha, X_train, y_train)\n",
    "X_new_cnn=np.concatenate((X_train,X_bim_perturbed_train))\n",
    "bim_cnn=cnn(X_new_cnn,new_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model - BIM-CNN:\n",
      "Accuracy Score: 0.7754784156653316\n"
     ]
    }
   ],
   "source": [
    "cnn_bim_predictions=get_result(bim_cnn, X_test, y_test, \"BIM-CNN\")\n",
    "#plot_predictions(y_test, cnn_bim_predictions, \"BIM-CNN model (Clean)\", xLabel=\"Time\", yLabel=\"Power Consumption\", realLabel=\"Actual power consumption\", predictedLabel=\"Predicted power consumption\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model - BIM-CNN:\n",
      "Accuracy Score: 0.764797507788162\n"
     ]
    }
   ],
   "source": [
    "cnn_bim_predictions=get_result(bim_cnn, X_bim_perturbed_cnn, y_test, \"BIM-CNN\")\n",
    "#plot_predictions(y_test, cnn_bim_predictions, \"BIM-CNN model (Perturbed)\", xLabel=\"Time\", yLabel=\"Power Consumption\", realLabel=\"Actual power consumption\", predictedLabel=\"Predicted power consumption\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_4 (Conv1D)           (None, 12, 64)            256       \n",
      "                                                                 \n",
      " max_pooling1d_4 (MaxPooling  (None, 4, 64)            0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_36 (Dense)            (None, 30)                7710      \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 10)                310       \n",
      "                                                                 \n",
      " dense_38 (Dense)            (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,287\n",
      "Trainable params: 8,287\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "656/656 [==============================] - 2s 1ms/step - loss: 0.4660\n",
      "Epoch 2/50\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2442\n",
      "Epoch 3/50\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2810\n",
      "Epoch 4/50\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.3003\n",
      "Epoch 5/50\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2371\n",
      "Epoch 6/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.2297\n",
      "Epoch 7/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.2284\n",
      "Epoch 8/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.2293\n",
      "Epoch 9/50\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2298\n",
      "Epoch 10/50\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2265\n",
      "Epoch 11/50\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2209\n",
      "Epoch 12/50\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2191\n",
      "Epoch 13/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.2175\n",
      "Epoch 14/50\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2167\n",
      "Epoch 15/50\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2157\n",
      "Epoch 16/50\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2121\n",
      "Epoch 17/50\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2091\n",
      "Epoch 18/50\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2059\n",
      "Epoch 19/50\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2095\n",
      "Epoch 20/50\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2051\n",
      "Epoch 21/50\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.2049\n",
      "Epoch 22/50\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.1983\n",
      "Epoch 23/50\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.1961\n",
      "Epoch 24/50\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.1950\n",
      "Epoch 25/50\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.1937\n",
      "Epoch 26/50\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.1929\n",
      "Epoch 27/50\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.1913\n",
      "Epoch 28/50\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.1901\n",
      "Epoch 29/50\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.1897\n",
      "Epoch 30/50\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.1874\n",
      "Epoch 31/50\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.1861\n",
      "Epoch 32/50\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.1857\n",
      "Epoch 33/50\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.1848\n",
      "Epoch 34/50\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.1835\n",
      "Epoch 35/50\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.1820\n",
      "Epoch 36/50\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.1818\n",
      "Epoch 37/50\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.1803\n",
      "Epoch 38/50\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.1788\n",
      "Epoch 39/50\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.1791\n",
      "Epoch 40/50\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.1783\n",
      "Epoch 41/50\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.1774\n",
      "Epoch 42/50\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.1763\n",
      "Epoch 43/50\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.1758\n",
      "Epoch 44/50\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.1754\n",
      "Epoch 45/50\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.1737\n",
      "Epoch 46/50\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.1731\n",
      "Epoch 47/50\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.1730\n",
      "Epoch 48/50\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.1723\n",
      "Epoch 49/50\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.1727\n",
      "Epoch 50/50\n",
      "656/656 [==============================] - 1s 1ms/step - loss: 0.1709\n"
     ]
    }
   ],
   "source": [
    "# Create perturbed training set\n",
    "X_pgd_perturbed_train = pgd(5, epsilon, alpha, X_train, y_train)\n",
    "X_new_cnn=np.concatenate((X_train,X_pgd_perturbed_train))\n",
    "pgd_cnn=cnn(X_new_cnn,new_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model - PGD-CNN:\n",
      "Accuracy Score: 0.7630173564753004\n"
     ]
    }
   ],
   "source": [
    "cnn_pgd_predictions=get_result(pgd_cnn, X_test, y_test, \"PGD-CNN\")\n",
    "#plot_predictions(y_test, cnn_pgd_predictions, \"PGD-CNN model (Clean)\", xLabel=\"Time\", yLabel=\"Power Consumption\", realLabel=\"Actual power consumption\", predictedLabel=\"Predicted power consumption\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model - PGD-CNN:\n",
      "Accuracy Score: 0.6680017801513128\n"
     ]
    }
   ],
   "source": [
    "cnn_pgd_predictions=get_result(pgd_cnn, X_pgd_perturbed_cnn, y_test, \"PGD-CNN\")\n",
    "#plot_predictions(y_test, cnn_pgd_predictions, \"PGD-CNN model (Perturbed)\", xLabel=\"Time\", yLabel=\"Power Consumption\", realLabel=\"Actual power consumption\", predictedLabel=\"Predicted power consumption\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN_LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_29\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " time_distributed_3 (TimeDis  (None, None, 13, 64)     192       \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " time_distributed_4 (TimeDis  (None, None, 6, 64)      0         \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " time_distributed_5 (TimeDis  (None, None, 384)        0         \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " lstm_17 (LSTM)              (None, 15)                24000     \n",
      "                                                                 \n",
      " dense_39 (Dense)            (None, 1)                 16        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24,208\n",
      "Trainable params: 24,208\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "656/656 [==============================] - 4s 2ms/step - loss: 0.2577\n",
      "Epoch 2/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.2299\n",
      "Epoch 3/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.2253\n",
      "Epoch 4/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.2225\n",
      "Epoch 5/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.2206\n",
      "Epoch 6/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.2181\n",
      "Epoch 7/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.2158\n",
      "Epoch 8/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.2137\n",
      "Epoch 9/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.2104\n",
      "Epoch 10/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.2077\n",
      "Epoch 11/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.2069\n",
      "Epoch 12/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.4185\n",
      "Epoch 13/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.2017\n",
      "Epoch 14/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1987\n",
      "Epoch 15/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1953\n",
      "Epoch 16/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1934\n",
      "Epoch 17/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1900\n",
      "Epoch 18/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1882\n",
      "Epoch 19/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1859\n",
      "Epoch 20/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1841\n",
      "Epoch 21/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1826\n",
      "Epoch 22/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1799\n",
      "Epoch 23/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1787\n",
      "Epoch 24/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1769\n",
      "Epoch 25/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1754\n",
      "Epoch 26/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1741\n",
      "Epoch 27/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1754\n",
      "Epoch 28/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1719\n",
      "Epoch 29/50\n",
      "656/656 [==============================] - 2s 3ms/step - loss: 0.1697\n",
      "Epoch 30/50\n",
      "656/656 [==============================] - 2s 2ms/step - loss: 0.1686\n",
      "Epoch 31/50\n",
      "656/656 [==============================] - 2s 2ms/step - loss: 0.1668\n",
      "Epoch 32/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1663\n",
      "Epoch 33/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1646\n",
      "Epoch 34/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1632\n",
      "Epoch 35/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1620\n",
      "Epoch 36/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1606\n",
      "Epoch 37/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1590\n",
      "Epoch 38/50\n",
      "656/656 [==============================] - 2s 2ms/step - loss: 0.1583\n",
      "Epoch 39/50\n",
      "656/656 [==============================] - 2s 2ms/step - loss: 0.1573\n",
      "Epoch 40/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1559\n",
      "Epoch 41/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1549\n",
      "Epoch 42/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1540\n",
      "Epoch 43/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1527\n",
      "Epoch 44/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1523\n",
      "Epoch 45/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1510\n",
      "Epoch 46/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1507\n",
      "Epoch 47/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1496\n",
      "Epoch 48/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1492\n",
      "Epoch 49/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1481\n",
      "Epoch 50/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1471\n"
     ]
    }
   ],
   "source": [
    "# Create perturbed training set\n",
    "X_fgsm_perturbed_train = fgsm(X_train, y_train)\n",
    "X_new_cnnlstm=np.concatenate((X_train,X_fgsm_perturbed_train))\n",
    "fgsm_cnnlstm=cnn_lstm(X_new_cnnlstm,new_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model - CNN-LSTM:\n",
      "Accuracy Score: 0.7777036048064085\n"
     ]
    }
   ],
   "source": [
    "cnnlstm_fgsm_predictions=get_result(fgsm_cnnlstm, X_test.reshape((X_test.shape[0], n_seq, X_test.shape[1], 1)), y_test, \"CNN-LSTM\")\n",
    "#plot_predictions(y_test, cnnlstm_fgsm_predictions, \"FGSM-CNNLSTM model (Clean)\", xLabel=\"Time\", yLabel=\"Power Consumption\", realLabel=\"Actual power consumption\", predictedLabel=\"Predicted power consumption\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model - CNN-LSTM:\n",
      "Accuracy Score: 0.737427681352915\n"
     ]
    }
   ],
   "source": [
    "cnnlstm_fgsm_predictions=get_result(fgsm_cnnlstm, X_fgsm_perturbed_cnnlstm.reshape((X_fgsm_perturbed_cnnlstm.shape[0], n_seq, X_bim_perturbed_cnnlstm.shape[1], 1)), y_test, \"CNN-LSTM\")\n",
    "#plot_predictions(y_test, cnnlstm_fgsm_predictions, \"FGSM-CNNLSTM model (Perturbed)\", xLabel=\"Time\", yLabel=\"Power Consumption\", realLabel=\"Actual power consumption\", predictedLabel=\"Predicted power consumption\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_30\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " time_distributed_6 (TimeDis  (None, None, 13, 64)     192       \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " time_distributed_7 (TimeDis  (None, None, 6, 64)      0         \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " time_distributed_8 (TimeDis  (None, None, 384)        0         \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " lstm_18 (LSTM)              (None, 15)                24000     \n",
      "                                                                 \n",
      " dense_40 (Dense)            (None, 1)                 16        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24,208\n",
      "Trainable params: 24,208\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "656/656 [==============================] - 8s 2ms/step - loss: 0.4812\n",
      "Epoch 2/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.2315A: 0s - los\n",
      "Epoch 3/50\n",
      "656/656 [==============================] - 2s 2ms/step - loss: 0.2285\n",
      "Epoch 4/50\n",
      "656/656 [==============================] - 2s 2ms/step - loss: 0.2263A: 0s -\n",
      "Epoch 5/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.2243\n",
      "Epoch 6/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.2224\n",
      "Epoch 7/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.2207\n",
      "Epoch 8/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.2188\n",
      "Epoch 9/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.2167\n",
      "Epoch 10/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.2155\n",
      "Epoch 11/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.2132\n",
      "Epoch 12/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.2109\n",
      "Epoch 13/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.2081\n",
      "Epoch 14/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.2067\n",
      "Epoch 15/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.2046\n",
      "Epoch 16/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.2019\n",
      "Epoch 17/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.2047\n",
      "Epoch 18/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1974\n",
      "Epoch 19/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1951\n",
      "Epoch 20/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1920\n",
      "Epoch 21/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1899\n",
      "Epoch 22/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1880\n",
      "Epoch 23/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1855\n",
      "Epoch 24/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1823\n",
      "Epoch 25/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1791\n",
      "Epoch 26/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1762\n",
      "Epoch 27/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1728\n",
      "Epoch 28/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1706\n",
      "Epoch 29/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1682\n",
      "Epoch 30/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1662\n",
      "Epoch 31/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1635\n",
      "Epoch 32/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1615\n",
      "Epoch 33/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1604\n",
      "Epoch 34/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1588\n",
      "Epoch 35/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1575\n",
      "Epoch 36/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1552\n",
      "Epoch 37/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1538\n",
      "Epoch 38/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1531\n",
      "Epoch 39/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1515\n",
      "Epoch 40/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1503\n",
      "Epoch 41/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1503\n",
      "Epoch 42/50\n",
      "656/656 [==============================] - 2s 2ms/step - loss: 0.1487\n",
      "Epoch 43/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1477\n",
      "Epoch 44/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1467\n",
      "Epoch 45/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1459\n",
      "Epoch 46/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1448\n",
      "Epoch 47/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1437\n",
      "Epoch 48/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1431\n",
      "Epoch 49/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1424\n",
      "Epoch 50/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1422\n"
     ]
    }
   ],
   "source": [
    "# Create perturbed training set\n",
    "X_bim_perturbed_train = bim(5, epsilon, alpha, X_train, y_train)\n",
    "X_new_cnnlstm=np.concatenate((X_train,X_bim_perturbed_train))\n",
    "bim_cnnlstm=cnn_lstm(X_new_cnnlstm,new_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model - CNN-LSTM:\n",
      "Accuracy Score: 0.7948375611927013\n"
     ]
    }
   ],
   "source": [
    "cnnlstm_bim_predictions=get_result(bim_cnnlstm, X_test.reshape((X_test.shape[0], n_seq, X_test.shape[1], 1)), y_test, \"CNN-LSTM\")\n",
    "#plot_predictions(y_test, cnnlstm_bim_predictions, \"BIM-CNNLSTM model (Clean)\", xLabel=\"Time\", yLabel=\"Power Consumption\", realLabel=\"Actual power consumption\", predictedLabel=\"Predicted power consumption\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model - CNN-LSTM:\n",
      "Accuracy Score: 0.7890520694259012\n"
     ]
    }
   ],
   "source": [
    "cnnlstm_bim_predictions=get_result(bim_cnnlstm, X_bim_perturbed_cnnlstm.reshape((X_bim_perturbed_cnnlstm.shape[0], n_seq, X_bim_perturbed_cnnlstm.shape[1], 1)), y_test, \"CNN-LSTM\")\n",
    "#plot_predictions(y_test, cnnlstm_bim_predictions, \"BIM-CNNLSTM model (Perturbed)\", xLabel=\"Time\", yLabel=\"Power Consumption\", realLabel=\"Actual power consumption\", predictedLabel=\"Predicted power consumption\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_31\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " time_distributed_9 (TimeDis  (None, None, 13, 64)     192       \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " time_distributed_10 (TimeDi  (None, None, 6, 64)      0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_11 (TimeDi  (None, None, 384)        0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " lstm_19 (LSTM)              (None, 15)                24000     \n",
      "                                                                 \n",
      " dense_41 (Dense)            (None, 1)                 16        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24,208\n",
      "Trainable params: 24,208\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "656/656 [==============================] - 4s 3ms/step - loss: 0.5521\n",
      "Epoch 2/50\n",
      "656/656 [==============================] - 2s 2ms/step - loss: 0.2519A: 0s - loss: 0.2\n",
      "Epoch 3/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.2495\n",
      "Epoch 4/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.2355\n",
      "Epoch 5/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.2258\n",
      "Epoch 6/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.2316\n",
      "Epoch 7/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.3455\n",
      "Epoch 8/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.2403\n",
      "Epoch 9/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.2232A: 0s \n",
      "Epoch 10/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.2226\n",
      "Epoch 11/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.2214\n",
      "Epoch 12/50\n",
      "656/656 [==============================] - 2s 2ms/step - loss: 0.2201\n",
      "Epoch 13/50\n",
      "656/656 [==============================] - 2s 2ms/step - loss: 0.2283A: 0s - loss: 0.\n",
      "Epoch 14/50\n",
      "656/656 [==============================] - 2s 3ms/step - loss: 0.2906\n",
      "Epoch 15/50\n",
      "656/656 [==============================] - 2s 2ms/step - loss: 0.2194\n",
      "Epoch 16/50\n",
      "656/656 [==============================] - 2s 2ms/step - loss: 0.2177\n",
      "Epoch 17/50\n",
      "656/656 [==============================] - 2s 3ms/step - loss: 0.2159\n",
      "Epoch 18/50\n",
      "656/656 [==============================] - 2s 2ms/step - loss: 0.2147\n",
      "Epoch 19/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.2132\n",
      "Epoch 20/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.2110\n",
      "Epoch 21/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.2093\n",
      "Epoch 22/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.2683\n",
      "Epoch 23/50\n",
      "656/656 [==============================] - 2s 2ms/step - loss: 0.2070\n",
      "Epoch 24/50\n",
      "656/656 [==============================] - 2s 2ms/step - loss: 0.2054\n",
      "Epoch 25/50\n",
      "656/656 [==============================] - 2s 2ms/step - loss: 0.2038\n",
      "Epoch 26/50\n",
      "656/656 [==============================] - 2s 3ms/step - loss: 0.2022\n",
      "Epoch 27/50\n",
      "656/656 [==============================] - 2s 3ms/step - loss: 0.2004\n",
      "Epoch 28/50\n",
      "656/656 [==============================] - 2s 3ms/step - loss: 0.1993\n",
      "Epoch 29/50\n",
      "656/656 [==============================] - 2s 2ms/step - loss: 0.1974\n",
      "Epoch 30/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1958\n",
      "Epoch 31/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1942\n",
      "Epoch 32/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1930\n",
      "Epoch 33/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1925\n",
      "Epoch 34/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1906\n",
      "Epoch 35/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1897\n",
      "Epoch 36/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1887\n",
      "Epoch 37/50\n",
      "656/656 [==============================] - 2s 2ms/step - loss: 0.1876\n",
      "Epoch 38/50\n",
      "656/656 [==============================] - 2s 3ms/step - loss: 0.1862\n",
      "Epoch 39/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1854\n",
      "Epoch 40/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1847\n",
      "Epoch 41/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1833\n",
      "Epoch 42/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1827\n",
      "Epoch 43/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1819A:\n",
      "Epoch 44/50\n",
      "656/656 [==============================] - 2s 3ms/step - loss: 0.1810\n",
      "Epoch 45/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1805\n",
      "Epoch 46/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1799A: 0s - loss: 0.179\n",
      "Epoch 47/50\n",
      "656/656 [==============================] - 2s 2ms/step - loss: 0.1789\n",
      "Epoch 48/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1786\n",
      "Epoch 49/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1777\n",
      "Epoch 50/50\n",
      "656/656 [==============================] - 1s 2ms/step - loss: 0.1772\n"
     ]
    }
   ],
   "source": [
    "# Create perturbed training set\n",
    "X_pgd_perturbed_train = pgd(5, epsilon, alpha, X_train, y_train)\n",
    "X_new_cnnlstm=np.concatenate((X_train,X_pgd_perturbed_train))\n",
    "pgd_cnnlstm=cnn_lstm(X_new_cnnlstm,new_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model - CNN-LSTM:\n",
      "Accuracy Score: 0.7596795727636849\n"
     ]
    }
   ],
   "source": [
    "cnnlstm_pgd_predictions=get_result(pgd_cnnlstm, X_test.reshape((X_test.shape[0], n_seq, X_test.shape[1], 1)), y_test, \"CNN-LSTM\")\n",
    "#plot_predictions(y_test, cnnlstm_pgd_predictions, \"PGD-CNNLSTM model (Clean)\", xLabel=\"Time\", yLabel=\"Power Consumption\", realLabel=\"Actual power consumption\", predictedLabel=\"Predicted power consumption\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model - CNN-LSTM:\n",
      "Accuracy Score: 0.6800178015131286\n"
     ]
    }
   ],
   "source": [
    "cnnlstm_pgd_predictions=get_result(pgd_cnnlstm, X_pgd_perturbed_cnnlstm.reshape((X_pgd_perturbed_cnnlstm.shape[0], n_seq, X_pgd_perturbed_cnnlstm.shape[1], 1)), y_test, \"CNN-LSTM\")\n",
    "#plot_predictions(y_test, cnnlstm_pgd_predictions, \"PGD-CNNLSTM model (Perturbed)\", xLabel=\"Time\", yLabel=\"Power Consumption\", realLabel=\"Actual power consumption\", predictedLabel=\"Predicted power consumption\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ConvLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_32\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv_lstm2d_1 (ConvLSTM2D)  (None, 1, 13, 64)         33536     \n",
      "                                                                 \n",
      " flatten_9 (Flatten)         (None, 832)               0         \n",
      "                                                                 \n",
      " dense_42 (Dense)            (None, 20)                16660     \n",
      "                                                                 \n",
      " dense_43 (Dense)            (None, 10)                210       \n",
      "                                                                 \n",
      " dense_44 (Dense)            (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50,417\n",
      "Trainable params: 50,417\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "656/656 [==============================] - 6s 4ms/step - loss: 0.2411\n",
      "Epoch 2/50\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.2254\n",
      "Epoch 3/50\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.2161\n",
      "Epoch 4/50\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.2018\n",
      "Epoch 5/50\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.1917\n",
      "Epoch 6/50\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.1827\n",
      "Epoch 7/50\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.1768\n",
      "Epoch 8/50\n",
      "656/656 [==============================] - 3s 5ms/step - loss: 0.1729\n",
      "Epoch 9/50\n",
      "656/656 [==============================] - 3s 5ms/step - loss: 0.1745\n",
      "Epoch 10/50\n",
      "656/656 [==============================] - 4s 5ms/step - loss: 0.1657\n",
      "Epoch 11/50\n",
      "656/656 [==============================] - 3s 5ms/step - loss: 0.1633\n",
      "Epoch 12/50\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.1619\n",
      "Epoch 13/50\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.1599\n",
      "Epoch 14/50\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.1587\n",
      "Epoch 15/50\n",
      "656/656 [==============================] - 3s 5ms/step - loss: 0.1565\n",
      "Epoch 16/50\n",
      "656/656 [==============================] - 3s 5ms/step - loss: 0.1555\n",
      "Epoch 17/50\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.1538\n",
      "Epoch 18/50\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.1521\n",
      "Epoch 19/50\n",
      "656/656 [==============================] - 3s 5ms/step - loss: 0.1511\n",
      "Epoch 20/50\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.1496\n",
      "Epoch 21/50\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.1509\n",
      "Epoch 22/50\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.1591\n",
      "Epoch 23/50\n",
      "656/656 [==============================] - 3s 5ms/step - loss: 0.1493\n",
      "Epoch 24/50\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.1448\n",
      "Epoch 25/50\n",
      "656/656 [==============================] - 3s 5ms/step - loss: 0.1443\n",
      "Epoch 26/50\n",
      "656/656 [==============================] - 3s 5ms/step - loss: 0.1427\n",
      "Epoch 27/50\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.1418\n",
      "Epoch 28/50\n",
      "656/656 [==============================] - 3s 5ms/step - loss: 0.1414\n",
      "Epoch 29/50\n",
      "656/656 [==============================] - 4s 6ms/step - loss: 0.1400\n",
      "Epoch 30/50\n",
      "656/656 [==============================] - 3s 5ms/step - loss: 0.1394\n",
      "Epoch 31/50\n",
      "656/656 [==============================] - 3s 5ms/step - loss: 0.1384\n",
      "Epoch 32/50\n",
      "656/656 [==============================] - 3s 5ms/step - loss: 0.1374\n",
      "Epoch 33/50\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.1365\n",
      "Epoch 34/50\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.1358\n",
      "Epoch 35/50\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.1353\n",
      "Epoch 36/50\n",
      "656/656 [==============================] - 3s 5ms/step - loss: 0.1348\n",
      "Epoch 37/50\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.1342\n",
      "Epoch 38/50\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.1322\n",
      "Epoch 39/50\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.1322\n",
      "Epoch 40/50\n",
      "656/656 [==============================] - 3s 5ms/step - loss: 0.1317A: 0s -\n",
      "Epoch 41/50\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.1307\n",
      "Epoch 42/50\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.1301\n",
      "Epoch 43/50\n",
      "656/656 [==============================] - 3s 5ms/step - loss: 0.1296\n",
      "Epoch 44/50\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.1286\n",
      "Epoch 45/50\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.1285\n",
      "Epoch 46/50\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.1274\n",
      "Epoch 47/50\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.1269\n",
      "Epoch 48/50\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.1262\n",
      "Epoch 49/50\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.1258\n",
      "Epoch 50/50\n",
      "656/656 [==============================] - 3s 5ms/step - loss: 0.1253\n"
     ]
    }
   ],
   "source": [
    "# Create perturbed training set\n",
    "X_fgsm_perturbed_train = fgsm(X_train, y_train, epsilon)\n",
    "X_new_convlstm=np.concatenate((X_train,X_fgsm_perturbed_train))\n",
    "fgsm_convlstm=convlstm(X_new_convlstm,new_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model - ConvLSTM:\n",
      "Accuracy Score: 0.8055184690698709\n"
     ]
    }
   ],
   "source": [
    "convlstm_fgsm_predictions=get_result(fgsm_convlstm, X_test.reshape((X_test.shape[0], n_seq,1, X_test.shape[1], 1)), y_test, \"ConvLSTM\")\n",
    "#plot_predictions(y_test, convlstm_fgsm_predictions, \"FGSM-CNNLSTM model (Clean)\", xLabel=\"Time\", yLabel=\"Power Consumption\", realLabel=\"Actual power consumption\", predictedLabel=\"Predicted power consumption\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model - ConvLSTM:\n",
      "Accuracy Score: 0.8050734312416555\n"
     ]
    }
   ],
   "source": [
    "convlstm_fgsm_predictions=get_result(fgsm_convlstm, X_fgsm_perturbed_convlstm.reshape((X_fgsm_perturbed_convlstm.shape[0], n_seq,1, X_bim_perturbed_convlstm.shape[1], 1)), y_test, \"ConvLSTM\")\n",
    "#plot_predictions(y_test, convlstm_fgsm_predictions, \"FGSM-ConvLSTM model (Perturbed)\", xLabel=\"Time\", yLabel=\"Power Consumption\", realLabel=\"Actual power consumption\", predictedLabel=\"Predicted power consumption\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_33\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv_lstm2d_2 (ConvLSTM2D)  (None, 1, 13, 64)         33536     \n",
      "                                                                 \n",
      " flatten_10 (Flatten)        (None, 832)               0         \n",
      "                                                                 \n",
      " dense_45 (Dense)            (None, 20)                16660     \n",
      "                                                                 \n",
      " dense_46 (Dense)            (None, 10)                210       \n",
      "                                                                 \n",
      " dense_47 (Dense)            (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50,417\n",
      "Trainable params: 50,417\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "656/656 [==============================] - 7s 5ms/step - loss: 0.2479\n",
      "Epoch 2/50\n",
      "656/656 [==============================] - 3s 5ms/step - loss: 0.2485\n",
      "Epoch 3/50\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.2263\n",
      "Epoch 4/50\n",
      "656/656 [==============================] - 3s 5ms/step - loss: 0.2230\n",
      "Epoch 5/50\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.2225\n",
      "Epoch 6/50\n",
      "656/656 [==============================] - 3s 5ms/step - loss: 0.2314\n",
      "Epoch 7/50\n",
      "656/656 [==============================] - 3s 5ms/step - loss: 0.2153\n",
      "Epoch 8/50\n",
      "656/656 [==============================] - 3s 5ms/step - loss: 0.2110\n",
      "Epoch 9/50\n",
      "656/656 [==============================] - 3s 5ms/step - loss: 0.2044\n",
      "Epoch 10/50\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.1984\n",
      "Epoch 11/50\n",
      "656/656 [==============================] - 3s 5ms/step - loss: 0.1942\n",
      "Epoch 12/50\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.1887\n",
      "Epoch 13/50\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.1867\n",
      "Epoch 14/50\n",
      "656/656 [==============================] - 3s 5ms/step - loss: 0.1790\n",
      "Epoch 15/50\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.1746\n",
      "Epoch 16/50\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.1714\n",
      "Epoch 17/50\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.1680\n",
      "Epoch 18/50\n",
      "656/656 [==============================] - 4s 6ms/step - loss: 0.1658\n",
      "Epoch 19/50\n",
      "656/656 [==============================] - 5s 8ms/step - loss: 0.1625\n",
      "Epoch 20/50\n",
      "656/656 [==============================] - 6s 9ms/step - loss: 0.1600\n",
      "Epoch 21/50\n",
      "656/656 [==============================] - 4s 6ms/step - loss: 0.1625\n",
      "Epoch 22/50\n",
      "656/656 [==============================] - 3s 5ms/step - loss: 0.1572\n",
      "Epoch 23/50\n",
      "656/656 [==============================] - 4s 6ms/step - loss: 0.1552\n",
      "Epoch 24/50\n",
      "656/656 [==============================] - 4s 6ms/step - loss: 0.1534\n",
      "Epoch 25/50\n",
      "656/656 [==============================] - 4s 6ms/step - loss: 0.1520\n",
      "Epoch 26/50\n",
      "656/656 [==============================] - 4s 6ms/step - loss: 0.1509\n",
      "Epoch 27/50\n",
      "656/656 [==============================] - 3s 5ms/step - loss: 0.1591\n",
      "Epoch 28/50\n",
      "656/656 [==============================] - 4s 5ms/step - loss: 0.1520\n",
      "Epoch 29/50\n",
      "656/656 [==============================] - 4s 6ms/step - loss: 0.1479\n",
      "Epoch 30/50\n",
      "656/656 [==============================] - 4s 6ms/step - loss: 0.1466\n",
      "Epoch 31/50\n",
      "656/656 [==============================] - 5s 8ms/step - loss: 0.1456\n",
      "Epoch 32/50\n",
      "656/656 [==============================] - 7s 11ms/step - loss: 0.1444\n",
      "Epoch 33/50\n",
      "656/656 [==============================] - 5s 8ms/step - loss: 0.1440\n",
      "Epoch 34/50\n",
      "656/656 [==============================] - 4s 6ms/step - loss: 0.1427\n",
      "Epoch 35/50\n",
      "656/656 [==============================] - 3s 5ms/step - loss: 0.1413\n",
      "Epoch 36/50\n",
      "656/656 [==============================] - 4s 6ms/step - loss: 0.1407\n",
      "Epoch 37/50\n",
      "656/656 [==============================] - 4s 5ms/step - loss: 0.1436\n",
      "Epoch 38/50\n",
      "656/656 [==============================] - 4s 6ms/step - loss: 0.1384\n",
      "Epoch 39/50\n",
      "656/656 [==============================] - 4s 5ms/step - loss: 0.1378\n",
      "Epoch 40/50\n",
      "656/656 [==============================] - 4s 5ms/step - loss: 0.1366\n",
      "Epoch 41/50\n",
      "656/656 [==============================] - 4s 5ms/step - loss: 0.1359\n",
      "Epoch 42/50\n",
      "656/656 [==============================] - 4s 5ms/step - loss: 0.1358\n",
      "Epoch 43/50\n",
      "656/656 [==============================] - 4s 6ms/step - loss: 0.1350\n",
      "Epoch 44/50\n",
      "656/656 [==============================] - 6s 9ms/step - loss: 0.1340\n",
      "Epoch 45/50\n",
      "656/656 [==============================] - 7s 11ms/step - loss: 0.1331\n",
      "Epoch 46/50\n",
      "656/656 [==============================] - 6s 9ms/step - loss: 0.1324\n",
      "Epoch 47/50\n",
      "656/656 [==============================] - 5s 7ms/step - loss: 0.1317\n",
      "Epoch 48/50\n",
      "656/656 [==============================] - 3s 5ms/step - loss: 0.1306\n",
      "Epoch 49/50\n",
      "656/656 [==============================] - 4s 6ms/step - loss: 0.1310\n",
      "Epoch 50/50\n",
      "656/656 [==============================] - 4s 6ms/step - loss: 0.1301\n"
     ]
    }
   ],
   "source": [
    "# Create perturbed training set\n",
    "X_bim_perturbed_train = bim(5, epsilon, alpha, X_train, y_train)\n",
    "X_new_convlstm=np.concatenate((X_train,X_bim_perturbed_train))\n",
    "bim_convlstm=convlstm(X_new_convlstm,new_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model - ConvLSTM:\n",
      "Accuracy Score: 0.8153093012906097\n"
     ]
    }
   ],
   "source": [
    "convlstm_bim_predictions=get_result(bim_convlstm, X_test.reshape((X_test.shape[0], n_seq,1, X_test.shape[1], 1)), y_test, \"ConvLSTM\")\n",
    "#plot_predictions(y_test, convlstm_bim_predictions, \"BIM-ConvLSTM model (Clean)\", xLabel=\"Time\", yLabel=\"Power Consumption\", realLabel=\"Actual power consumption\", predictedLabel=\"Predicted power consumption\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model - ConvLSTM:\n",
      "Accuracy Score: 0.8097463284379173\n"
     ]
    }
   ],
   "source": [
    "convlstm_bim_predictions=get_result(bim_convlstm, X_bim_perturbed_convlstm.reshape((X_bim_perturbed_convlstm.shape[0], n_seq,1, X_bim_perturbed_convlstm.shape[1], 1)), y_test, \"ConvLSTM\")\n",
    "#plot_predictions(y_test, convlstm_bim_predictions, \"BIM-ConvLSTM model (Perturbed)\", xLabel=\"Time\", yLabel=\"Power Consumption\", realLabel=\"Actual power consumption\", predictedLabel=\"Predicted power consumption\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_34\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv_lstm2d_3 (ConvLSTM2D)  (None, 1, 13, 64)         33536     \n",
      "                                                                 \n",
      " flatten_11 (Flatten)        (None, 832)               0         \n",
      "                                                                 \n",
      " dense_48 (Dense)            (None, 20)                16660     \n",
      "                                                                 \n",
      " dense_49 (Dense)            (None, 10)                210       \n",
      "                                                                 \n",
      " dense_50 (Dense)            (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50,417\n",
      "Trainable params: 50,417\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "656/656 [==============================] - 7s 4ms/step - loss: 0.2549\n",
      "Epoch 2/50\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.2390\n",
      "Epoch 3/50\n",
      "656/656 [==============================] - 3s 5ms/step - loss: 0.2290\n",
      "Epoch 4/50\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.2248\n",
      "Epoch 5/50\n",
      "656/656 [==============================] - 3s 5ms/step - loss: 0.2225\n",
      "Epoch 6/50\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.2187\n",
      "Epoch 7/50\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.2146\n",
      "Epoch 8/50\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.2104\n",
      "Epoch 9/50\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.2048\n",
      "Epoch 10/50\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.2097\n",
      "Epoch 11/50\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.2018\n",
      "Epoch 12/50\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.1979\n",
      "Epoch 13/50\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.1961\n",
      "Epoch 14/50\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.1950\n",
      "Epoch 15/50\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.1939\n",
      "Epoch 16/50\n",
      "656/656 [==============================] - 3s 5ms/step - loss: 0.1918\n",
      "Epoch 17/50\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.1894\n",
      "Epoch 18/50\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.1882\n",
      "Epoch 19/50\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.1873\n",
      "Epoch 20/50\n",
      "656/656 [==============================] - 3s 5ms/step - loss: 0.1856\n",
      "Epoch 21/50\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.1850\n",
      "Epoch 22/50\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.1837\n",
      "Epoch 23/50\n",
      "656/656 [==============================] - 3s 5ms/step - loss: 0.1832\n",
      "Epoch 24/50\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.1828\n",
      "Epoch 25/50\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.1818\n",
      "Epoch 26/50\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.1810\n",
      "Epoch 27/50\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.1806\n",
      "Epoch 28/50\n",
      "656/656 [==============================] - 3s 5ms/step - loss: 0.1803\n",
      "Epoch 29/50\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.1821\n",
      "Epoch 30/50\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.1790\n",
      "Epoch 31/50\n",
      "656/656 [==============================] - 3s 5ms/step - loss: 0.1782\n",
      "Epoch 32/50\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.1778\n",
      "Epoch 33/50\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.1770\n",
      "Epoch 34/50\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.1765\n",
      "Epoch 35/50\n",
      "656/656 [==============================] - 3s 4ms/step - loss: 0.1763\n",
      "Epoch 36/50\n",
      "656/656 [==============================] - 5s 7ms/step - loss: 0.1756\n",
      "Epoch 37/50\n",
      "656/656 [==============================] - 5s 7ms/step - loss: 0.1754\n",
      "Epoch 38/50\n",
      "656/656 [==============================] - 7s 11ms/step - loss: 0.1750\n",
      "Epoch 39/50\n",
      "656/656 [==============================] - 6s 10ms/step - loss: 0.1749\n",
      "Epoch 40/50\n",
      "656/656 [==============================] - 4s 6ms/step - loss: 0.1739\n",
      "Epoch 41/50\n",
      "656/656 [==============================] - 3s 5ms/step - loss: 0.1735\n",
      "Epoch 42/50\n",
      "656/656 [==============================] - 3s 5ms/step - loss: 0.1732\n",
      "Epoch 43/50\n",
      "656/656 [==============================] - 4s 6ms/step - loss: 0.1731\n",
      "Epoch 44/50\n",
      "656/656 [==============================] - 4s 6ms/step - loss: 0.1738\n",
      "Epoch 45/50\n",
      "656/656 [==============================] - 4s 6ms/step - loss: 0.2402\n",
      "Epoch 46/50\n",
      "656/656 [==============================] - 4s 6ms/step - loss: 0.1725\n",
      "Epoch 47/50\n",
      "656/656 [==============================] - 4s 6ms/step - loss: 0.1715\n",
      "Epoch 48/50\n",
      "656/656 [==============================] - 4s 6ms/step - loss: 0.1708\n",
      "Epoch 49/50\n",
      "656/656 [==============================] - 4s 6ms/step - loss: 0.1704\n",
      "Epoch 50/50\n",
      "656/656 [==============================] - 3s 5ms/step - loss: 0.1707\n"
     ]
    }
   ],
   "source": [
    "X_pgd_perturbed_train = pgd(5, epsilon, alpha, X_train, y_train)\n",
    "X_new_convlstm=np.concatenate((X_train,X_pgd_perturbed_train))\n",
    "pgd_convlstm=convlstm(X_new_convlstm,new_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model - ConvLSTM:\n",
      "Accuracy Score: 0.7739207832665776\n"
     ]
    }
   ],
   "source": [
    "convlstm_pgd_predictions=get_result(pgd_convlstm, X_test.reshape((X_test.shape[0], n_seq,1, X_test.shape[1], 1)), y_test, \"ConvLSTM\")\n",
    "#plot_predictions(y_test, convlstm_pgd_predictions, \"PGD-ConvLSTM model (Clean)\", xLabel=\"Time\", yLabel=\"Power Consumption\", realLabel=\"Actual power consumption\", predictedLabel=\"Predicted power consumption\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model - ConvLSTM:\n",
      "Accuracy Score: 0.6800178015131286\n"
     ]
    }
   ],
   "source": [
    "convlstm_pgd_predictions=get_result(pgd_convlstm, X_pgd_perturbed_convlstm.reshape((X_pgd_perturbed_convlstm.shape[0], n_seq,1, X_pgd_perturbed_convlstm.shape[1], 1)), y_test, \"ConvLSTM\")\n",
    "#plot_predictions(y_test, convlstm_pgd_predictions, \"PGD-ConvLSTM model (Perturbed)\", xLabel=\"Time\", yLabel=\"Power Consumption\", realLabel=\"Actual power consumption\", predictedLabel=\"Predicted power consumption\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
